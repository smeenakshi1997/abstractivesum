{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "76dd073247584b3eb0267f92842bc089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_135e3af585954a0e998af97b0033201e",
              "IPY_MODEL_481057248883430ebdd3c21f60e4f1e7",
              "IPY_MODEL_ca394c476c8943388f07a9991d4b58ee"
            ],
            "layout": "IPY_MODEL_9704e51829b640319c7228e18d32cef3"
          }
        },
        "135e3af585954a0e998af97b0033201e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98dc53c9dabd4c81a2122e188720dc9b",
            "placeholder": "​",
            "style": "IPY_MODEL_900cd2d148b941f48f19de5a38a0e83b",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "481057248883430ebdd3c21f60e4f1e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51c05828cb684a1cb58ee4313d1d07f9",
            "max": 1585,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1576a98e8db743bca6ad7d9efe30ea40",
            "value": 1585
          }
        },
        "ca394c476c8943388f07a9991d4b58ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0eedfddf45b42dc92c0314434852e2a",
            "placeholder": "​",
            "style": "IPY_MODEL_fcb9cef9e609465b9024c1c5aa9859fc",
            "value": " 1.58k/1.58k [00:00&lt;00:00, 60.6kB/s]"
          }
        },
        "9704e51829b640319c7228e18d32cef3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98dc53c9dabd4c81a2122e188720dc9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "900cd2d148b941f48f19de5a38a0e83b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51c05828cb684a1cb58ee4313d1d07f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1576a98e8db743bca6ad7d9efe30ea40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d0eedfddf45b42dc92c0314434852e2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcb9cef9e609465b9024c1c5aa9859fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7308d656bd394e77877ec33b48e5a58f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24a62e8e6aaf45beac522bf34d818a68",
              "IPY_MODEL_e66b821289674e95aabcd7d35e680734",
              "IPY_MODEL_25cc159161e84009b597486db7cd1669"
            ],
            "layout": "IPY_MODEL_09d8e58302984138b0904ccde87392a2"
          }
        },
        "24a62e8e6aaf45beac522bf34d818a68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d91da1a77b984acfbb196054825f7006",
            "placeholder": "​",
            "style": "IPY_MODEL_fd3e00144ce6423da7b934e557ce1cc9",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "e66b821289674e95aabcd7d35e680734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a5fdda1707046558779782c16400b0a",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9f155cc9e034bc4b9e79c942cf83b16",
            "value": 898823
          }
        },
        "25cc159161e84009b597486db7cd1669": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db40eca93af34e8490b62069bd2b4175",
            "placeholder": "​",
            "style": "IPY_MODEL_bb8ae03cbae04aa2946067760ce7222e",
            "value": " 899k/899k [00:00&lt;00:00, 20.9MB/s]"
          }
        },
        "09d8e58302984138b0904ccde87392a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d91da1a77b984acfbb196054825f7006": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd3e00144ce6423da7b934e557ce1cc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a5fdda1707046558779782c16400b0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9f155cc9e034bc4b9e79c942cf83b16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db40eca93af34e8490b62069bd2b4175": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb8ae03cbae04aa2946067760ce7222e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2b20c9457194afbb06d5bde4b874912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c7ea6ce794442f5a761cb97a7573c96",
              "IPY_MODEL_82ec7a40c0b6429884e6c08eab84bcab",
              "IPY_MODEL_804d2b456e0647d6bdd7deba7ab9f0f0"
            ],
            "layout": "IPY_MODEL_5b3e9aa395874d3b90330a610b6660b6"
          }
        },
        "8c7ea6ce794442f5a761cb97a7573c96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff0df9e13ef94f319ccceb19366390a8",
            "placeholder": "​",
            "style": "IPY_MODEL_7064502c8e444a198854c7d4361e26b0",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "82ec7a40c0b6429884e6c08eab84bcab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37df01ee202247c18f03d5befec00be2",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76553477e29b4e248871d8b01df28a44",
            "value": 456318
          }
        },
        "804d2b456e0647d6bdd7deba7ab9f0f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d61cfb7014e4fb6825140d50f544b97",
            "placeholder": "​",
            "style": "IPY_MODEL_7cd6b3f46ec04755aed2d855c3f8a393",
            "value": " 456k/456k [00:00&lt;00:00, 1.90MB/s]"
          }
        },
        "5b3e9aa395874d3b90330a610b6660b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff0df9e13ef94f319ccceb19366390a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7064502c8e444a198854c7d4361e26b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37df01ee202247c18f03d5befec00be2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76553477e29b4e248871d8b01df28a44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d61cfb7014e4fb6825140d50f544b97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cd6b3f46ec04755aed2d855c3f8a393": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46aabd91a13245b9aa3a10ec91631ef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85a2db97f1a7483e90f10d6a8a09b0cc",
              "IPY_MODEL_e8021aa01e76437eaf1a7f79b5917b15",
              "IPY_MODEL_0792f72f508a42c7a13e616591f00b5e"
            ],
            "layout": "IPY_MODEL_13e596f990bc45d19f42771f20af39fd"
          }
        },
        "85a2db97f1a7483e90f10d6a8a09b0cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bdae288ed744408b4106093bb2dd429",
            "placeholder": "​",
            "style": "IPY_MODEL_30a97447762f4e51a57bc8e8fdb639fb",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "e8021aa01e76437eaf1a7f79b5917b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da24ebde217548acb8f3b92ed19a0354",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06f0075af24f4886a5ab4b9097a5f643",
            "value": 1355863
          }
        },
        "0792f72f508a42c7a13e616591f00b5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c40140d90b7c428cb95fe8fad70bbb8f",
            "placeholder": "​",
            "style": "IPY_MODEL_c31c387e26b942f2bc8ff644ac7cbc51",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 16.4MB/s]"
          }
        },
        "13e596f990bc45d19f42771f20af39fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bdae288ed744408b4106093bb2dd429": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30a97447762f4e51a57bc8e8fdb639fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da24ebde217548acb8f3b92ed19a0354": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06f0075af24f4886a5ab4b9097a5f643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c40140d90b7c428cb95fe8fad70bbb8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c31c387e26b942f2bc8ff644ac7cbc51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87d3bfaada9c4719be91892c925111a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4382889c8b694ecda362b4e54cf15bdf",
              "IPY_MODEL_26b0e0d59e67402caa4a35554902b194",
              "IPY_MODEL_96b1760c6eb84f88a0e7deb8683ea4e6"
            ],
            "layout": "IPY_MODEL_ca90f4873f4244f1a650afe22e2e4d33"
          }
        },
        "4382889c8b694ecda362b4e54cf15bdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cd596d6de06431d83744bb7f8cf51e6",
            "placeholder": "​",
            "style": "IPY_MODEL_dbdb08dbeeec4ac1be6d76e5540a2b07",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "26b0e0d59e67402caa4a35554902b194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45cee4423c084ccfadae7479b4ed5171",
            "max": 1625270765,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68a8f9156f1947ebbec1dbedd54a2f24",
            "value": 1625270765
          }
        },
        "96b1760c6eb84f88a0e7deb8683ea4e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c1323a79fda43c88136929c435a0dc0",
            "placeholder": "​",
            "style": "IPY_MODEL_fc51e3bbb0444d989f656ef141e0e8e1",
            "value": " 1.63G/1.63G [01:03&lt;00:00, 23.7MB/s]"
          }
        },
        "ca90f4873f4244f1a650afe22e2e4d33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cd596d6de06431d83744bb7f8cf51e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbdb08dbeeec4ac1be6d76e5540a2b07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45cee4423c084ccfadae7479b4ed5171": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68a8f9156f1947ebbec1dbedd54a2f24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c1323a79fda43c88136929c435a0dc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc51e3bbb0444d989f656ef141e0e8e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fcac146f119c483cbf827f0e39a6cf23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a07861b41aa45a0b50e846b2624cfeb",
              "IPY_MODEL_d5223ffc030345099684bf733e8eb2a7",
              "IPY_MODEL_cffba9b60e63410eaf183e06f549aba4"
            ],
            "layout": "IPY_MODEL_b81ca28e0d7c4bf1a304710f1dad156d"
          }
        },
        "1a07861b41aa45a0b50e846b2624cfeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9edaf4931d384f8ca027416f942ef4c4",
            "placeholder": "​",
            "style": "IPY_MODEL_596a6de88e7b402c96bd1f9e3bb08180",
            "value": "Downloading (…)neration_config.json: 100%"
          }
        },
        "d5223ffc030345099684bf733e8eb2a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5598f9aedf954a769164b6274ad48907",
            "max": 363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc4aa627f5ee48fba711fc6df75d55a8",
            "value": 363
          }
        },
        "cffba9b60e63410eaf183e06f549aba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed296bac50614b00b2dbf61400b2b5a7",
            "placeholder": "​",
            "style": "IPY_MODEL_9e0459d7169a4299b070e97c555665cb",
            "value": " 363/363 [00:00&lt;00:00, 11.5kB/s]"
          }
        },
        "b81ca28e0d7c4bf1a304710f1dad156d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9edaf4931d384f8ca027416f942ef4c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "596a6de88e7b402c96bd1f9e3bb08180": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5598f9aedf954a769164b6274ad48907": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc4aa627f5ee48fba711fc6df75d55a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed296bac50614b00b2dbf61400b2b5a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e0459d7169a4299b070e97c555665cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6af9eada39694bd48fc00af2f4f3f736": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7645cf623934223afe1848a95d5bb91",
              "IPY_MODEL_c7610ef038d0484e908aa35890001180",
              "IPY_MODEL_86bf90726a504ea297c63bda1617ead6"
            ],
            "layout": "IPY_MODEL_e6b2474ddc5a4ca6ae28a95ec1308e63"
          }
        },
        "a7645cf623934223afe1848a95d5bb91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_236c36875393430b8bc5abdeeb4391a3",
            "placeholder": "​",
            "style": "IPY_MODEL_dced7766d52c4a99bced3c9bcdf12854",
            "value": "Downloading builder script: "
          }
        },
        "c7610ef038d0484e908aa35890001180": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b32074b8763347059fb0a15f413640e4",
            "max": 2169,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_86c449013db3408e9601966c59bdfe0d",
            "value": 2169
          }
        },
        "86bf90726a504ea297c63bda1617ead6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2eec6499d95a40f6888319a2b857d034",
            "placeholder": "​",
            "style": "IPY_MODEL_011608cad43f465b8abb84b60b3e5f9e",
            "value": " 5.65k/? [00:00&lt;00:00, 238kB/s]"
          }
        },
        "e6b2474ddc5a4ca6ae28a95ec1308e63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "236c36875393430b8bc5abdeeb4391a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dced7766d52c4a99bced3c9bcdf12854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b32074b8763347059fb0a15f413640e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86c449013db3408e9601966c59bdfe0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2eec6499d95a40f6888319a2b857d034": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "011608cad43f465b8abb84b60b3e5f9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45a924b098b84e6d88cbca08aaa75883": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd6db232d07f47aaa335fa4b9bdaa969",
              "IPY_MODEL_c955d2812fa94de6873f8eac663cfc8b",
              "IPY_MODEL_55725f79e5004dc9bd7a104dcb9a6548"
            ],
            "layout": "IPY_MODEL_f5cf7a987aa34c2f8e90bd7766f7217e"
          }
        },
        "fd6db232d07f47aaa335fa4b9bdaa969": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_510d66d080104750a8f0acf0b6c534ec",
            "placeholder": "​",
            "style": "IPY_MODEL_ef64a4aff3314bfd81980def50153389",
            "value": "Downloading builder script: "
          }
        },
        "c955d2812fa94de6873f8eac663cfc8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a777605da56f46f3a1c3d19acd156689",
            "max": 2923,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cfd823c1a3684ca9a898ebe3d37eaaed",
            "value": 2923
          }
        },
        "55725f79e5004dc9bd7a104dcb9a6548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cf35e4736364e8dba5dedefde44cb4e",
            "placeholder": "​",
            "style": "IPY_MODEL_050fab9dd897410ca544909485ffd565",
            "value": " 8.10k/? [00:00&lt;00:00, 402kB/s]"
          }
        },
        "f5cf7a987aa34c2f8e90bd7766f7217e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "510d66d080104750a8f0acf0b6c534ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef64a4aff3314bfd81980def50153389": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a777605da56f46f3a1c3d19acd156689": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfd823c1a3684ca9a898ebe3d37eaaed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8cf35e4736364e8dba5dedefde44cb4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "050fab9dd897410ca544909485ffd565": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d176649caf25402ca1f79bd94ecd0325": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e16b579bc168497081307cb2344bf4a8",
              "IPY_MODEL_38b1d971281b4ffd96a1ce1075d54e27",
              "IPY_MODEL_7fe33bd32d22401ab61d3c927e96ee16"
            ],
            "layout": "IPY_MODEL_bd9922b70bed4308ab9cc6cad3293ce0"
          }
        },
        "e16b579bc168497081307cb2344bf4a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75424f7915db46539867cd45c9e17a64",
            "placeholder": "​",
            "style": "IPY_MODEL_cc70b1c13c2b49faab45771b17624928",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "38b1d971281b4ffd96a1ce1075d54e27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04f0d20443c14a2a81d0022ffa1744c3",
            "max": 482,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67ba25be82d440499712326815b1abd7",
            "value": 482
          }
        },
        "7fe33bd32d22401ab61d3c927e96ee16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc619dc1dfb84eea8f88fac42d477b5c",
            "placeholder": "​",
            "style": "IPY_MODEL_404c35544f364bbea352a61a616ba3e0",
            "value": " 482/482 [00:00&lt;00:00, 16.6kB/s]"
          }
        },
        "bd9922b70bed4308ab9cc6cad3293ce0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75424f7915db46539867cd45c9e17a64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc70b1c13c2b49faab45771b17624928": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04f0d20443c14a2a81d0022ffa1744c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67ba25be82d440499712326815b1abd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc619dc1dfb84eea8f88fac42d477b5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "404c35544f364bbea352a61a616ba3e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf058328bd4c421f8e938ff0b5963304": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_32e6a9a4b709436dbe6ece900be10a03",
              "IPY_MODEL_913dc7366e21479db37d95f790fa4df4",
              "IPY_MODEL_d2f759cbad954607ae95236b2ad303af"
            ],
            "layout": "IPY_MODEL_6b58e41f8fac4cd1864d21f3f9cda42a"
          }
        },
        "32e6a9a4b709436dbe6ece900be10a03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e417b612c24d48b5bd8254c210178d0f",
            "placeholder": "​",
            "style": "IPY_MODEL_5cb78f3c2a6441a28fbbef231bd4aaaf",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "913dc7366e21479db37d95f790fa4df4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03b06ddbf235474fb46597275dd82188",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c54972622de941af8fbf85d4fc57ac8a",
            "value": 898823
          }
        },
        "d2f759cbad954607ae95236b2ad303af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b3e23403e2a4dd79626474f805e649a",
            "placeholder": "​",
            "style": "IPY_MODEL_b77dc1a175ed412684ce2ed6379a6e1a",
            "value": " 899k/899k [00:00&lt;00:00, 4.34MB/s]"
          }
        },
        "6b58e41f8fac4cd1864d21f3f9cda42a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e417b612c24d48b5bd8254c210178d0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cb78f3c2a6441a28fbbef231bd4aaaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03b06ddbf235474fb46597275dd82188": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c54972622de941af8fbf85d4fc57ac8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b3e23403e2a4dd79626474f805e649a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b77dc1a175ed412684ce2ed6379a6e1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "290f14b74a324c3eb14eede455050366": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7bdd20a3637a45f3a699d46f26cda390",
              "IPY_MODEL_d177f02485a34545a3d7fa788893d970",
              "IPY_MODEL_d0a7ebd4f06c4d8887847750817792af"
            ],
            "layout": "IPY_MODEL_4b7a27f3ea84413b9425c5d249263fce"
          }
        },
        "7bdd20a3637a45f3a699d46f26cda390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7b329ea7cff43699c5b0f18f2f04b93",
            "placeholder": "​",
            "style": "IPY_MODEL_168c1187a3b04368b70f50a6156888fd",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "d177f02485a34545a3d7fa788893d970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5c1af9767a740bd8a8310ee7c632552",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_913d388d1b684372a1603ccdf660170c",
            "value": 456318
          }
        },
        "d0a7ebd4f06c4d8887847750817792af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ed707f637e54ed098f8365e8773b8e7",
            "placeholder": "​",
            "style": "IPY_MODEL_edc07276177d464495d8c7052c73bee8",
            "value": " 456k/456k [00:00&lt;00:00, 6.02MB/s]"
          }
        },
        "4b7a27f3ea84413b9425c5d249263fce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7b329ea7cff43699c5b0f18f2f04b93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "168c1187a3b04368b70f50a6156888fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5c1af9767a740bd8a8310ee7c632552": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "913d388d1b684372a1603ccdf660170c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ed707f637e54ed098f8365e8773b8e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edc07276177d464495d8c7052c73bee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2460d5314f0d440d9338396ea345568c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08512ce8a719466ca82a89dddab40a6e",
              "IPY_MODEL_0c184a616d474355a71e2a44650a2ef1",
              "IPY_MODEL_017f184efe8e4222889999333db90448"
            ],
            "layout": "IPY_MODEL_826fd887504b416ca3d70a53a2889ff0"
          }
        },
        "08512ce8a719466ca82a89dddab40a6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6be8f4a68a7c414cb2b98fb1acaa548b",
            "placeholder": "​",
            "style": "IPY_MODEL_d9facb776c7544c5859026c6b6e99ce6",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "0c184a616d474355a71e2a44650a2ef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21f86f8cad994dc6ac3691f4e1c556fe",
            "max": 1425941629,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_64b8a4576b66452bb6bc4d675f4cfd7f",
            "value": 1425941629
          }
        },
        "017f184efe8e4222889999333db90448": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a06e4f1788cf4417a194a56e6076d73d",
            "placeholder": "​",
            "style": "IPY_MODEL_dde44eb2553b46e88160d2f5ef8d2132",
            "value": " 1.43G/1.43G [00:12&lt;00:00, 139MB/s]"
          }
        },
        "826fd887504b416ca3d70a53a2889ff0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6be8f4a68a7c414cb2b98fb1acaa548b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9facb776c7544c5859026c6b6e99ce6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21f86f8cad994dc6ac3691f4e1c556fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64b8a4576b66452bb6bc4d675f4cfd7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a06e4f1788cf4417a194a56e6076d73d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dde44eb2553b46e88160d2f5ef8d2132": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smeenakshi1997/abstractivesum/blob/main/Training_and_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers -Uqq\n",
        "!pip install datasets -Uqq\n",
        "!pip install bert-score -Uqq\n",
        "!pip install sacremoses\n",
        "!pip install ohmeow-blurr==0.0.24"
      ],
      "metadata": {
        "id": "PYmzm1SPU5JZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install fastai==2.3.1      #version varies with update in colab verify: https://github.com/ohmeow/blurr/issues/21\n",
        "#!pip install ohmeow-blurr==0.0.24      #version varies with update in colab verify: https://github.com/ohmeow/blurr/issues/21\n",
        "##!pip install git+https://github.com/huggingface/transformers\n",
        "##!pip install torch==1.7.1+cu111 -f https://download.pytorch.org/whl/cu111/torch_stable.html\n",
        "#!pip install transformers==4.3.3      #version varies with update in colab verify: https://github.com/ohmeow/blurr/issues/21\n",
        "#!pip install bert-score -q"
      ],
      "metadata": {
        "id": "bKEBF4caHLCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from fastai.text.all import *\n",
        "from transformers import *\n",
        "from blurr.data.all import *\n",
        "from blurr.modeling.all import *"
      ],
      "metadata": {
        "id": "roq3_3SYm4_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('API SAMPEL DATA.csv', error_bad_lines=False, sep=';', engine='python')\n",
        "df = df.dropna().reset_index()"
      ],
      "metadata": {
        "id": "NgyOuxO3rIBb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "405196c1-c6cd-4771-a21a-3a2e77331e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-67981ca74a15>:1: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df = pd.read_csv('SampleData (1).csv', error_bad_lines=False, sep=';', engine='python')\n",
            "Skipping line 14: ';' expected after '\"'\n",
            "Skipping line 16: ';' expected after '\"'\n",
            "Skipping line 19: ';' expected after '\"'\n",
            "Skipping line 20: ';' expected after '\"'\n",
            "Skipping line 24: ';' expected after '\"'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Clean text\n",
        "df['content'] = df['content'].apply(lambda x: x.replace('/',''))\n",
        "df['content'] = df['content'].apply(lambda x: x.replace('\\xa0',''))\n",
        "df['content'] = df['content'].apply(lambda x: x.replace(':-',':'))\n",
        "df['content'] = df['content'].apply(lambda x: x.replace('.-','.'))\n",
        "df['content'] = df['content'].apply(lambda x: x.replace(' ,',', '))\n",
        "df['content'] = df['content'].apply(lambda x: x.replace('.','. '))\n",
        "df['content'] = df['content'].apply(lambda x: x.replace('  ',' '))\n",
        "df.head()"
      ],
      "metadata": {
        "id": "SlC_o9Asrexf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c78e6738-49b0-48b8-f2c5-c95229252e63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   level_0  index  \\\n",
              "0        0      1   \n",
              "1        1      2   \n",
              "2        2      3   \n",
              "3        3      4   \n",
              "4        4      5   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   content  \\\n",
              "0  Innovative impacts of Chief Minister's Relief Fund application developed for Chief Minister's Office, RTI Online application, RTI Portal forGovernment of Maharashtra: Bilingual application in open source technology. Work flow based ICT solution- Ease in decision making through proper monitoring- Citizen centric services are easily accessible to common citizens- User friendly application- Role based application processing- Reduction in human interferences- Regular decisions and calculations are inbuilt in the application so that they are devoid of human error. Yield of best practices and te...   \n",
              "1  1. Chief Ministers Relief Fund Application- Requirement analysis, Designing and Development and security auditing and Maintenance of Chief Ministers Relief Fund web based Bilingual Application for Chief Ministers Office, Government of Maharashtra using Open source technology in MVC model (Platform: Java, Struts2,PostgreSQL)- For this entire SDLC is followed and with special emphasis on users requirement specifications. Developed modules consisting of Citizen Centric Services like online donation and online application submission, Payment verification, Receipt generation, Enquiry services u...   \n",
              "2                                                                                                                                                                                                                                                                                                                                                          - Chief Ministers Relief Fund application enabled citizens to donate money to Chief Ministers office from any geographical location using online payment gateway with ease, with a feature of online receipt generation which citizen can use for Income tax ex   \n",
              "3  The technical coordination, the IT support to the various user department has always been done in the situation effective and efficacious manner. In order to make the district digitally efficacious and well benefited of the digital india schemes and vaious e-governance projects the implementation of the project were done timely and to the proper stake holders of a project. The various offices of the government in the district like transport,registry,mining offices were made cashless yielding a very transparent and corruption free environment. The BCC course and Tally course were tagged wit...   \n",
              "4  To analyse a technical matter and to provide its systematic, IT based situation-effective solution to the user department in the district. To model and manage the databases of Polling Personnels,EVM,Booths, and prepare various randomization reports in the LITTIPARA assembly bye-election 2017. To render the technical coordination for an effective IT based solution in various e-governance projects of state and central level. To work as a technical IT support adviser to DC of the district. To impart training on various e-governance project to the respective user departments. To solve the tech...   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     title  \n",
              "0                                                                                                                                                                                                                                                                      The officer was involved in - Development and implementation of Chief Minister's Relief Fund application, RTI Online application, RTI Portal, SIMNIC and Credit Sales - Product enhancement for CMRF project - Development of Bilingual, responsive application in open source technology. - Management on Servers Web and DB with backup mechanism  \n",
              "1  The officer was involved in - Requirement analysis, Designing and Development and security auditing and Maintenance of web based Chief Ministers Relief Fund project - Bilingual Application for Chief Ministers Office, using Open source technology in MVC model (Platform:Java, Struts2, PostgreSQL) - Citizen Centric Services like online donation and online application submission, Payment verification, Receipt generation, Enquiry services using Payment Gateway with SMS, Email integration. - Implementation of RTI online and RTI Portal - Coordination in Implementation, Training and Support of Mah...  \n",
              "2                                                                                                                                                                     The officer was involved in - Design, development and implementation of ief Ministers Relief Fund application with integration of payment gateway, SMS and e-Mail. - Implementation of RTI Online application with payment gateway integration - Writing Shell Scripts and cron for service availability - Credit and Sales monitoring application - Development of Multidepartment projects locally in Open Source along with server administration  \n",
              "3                                                                                                                                                                        The Officer was involved - Implementation of digital india schemes and vaious e- governance projects - Migrated the district website under S3WaaS framework - Providing technical support for all the elections in the district - Implemented PMKISAN and CMKAY project in the district - Tested and implemented different software like EPMIS, Food DBT Portal, Force Deployment Portal, Covid registration portal, AApda Sampoorti portal etc..  \n",
              "4                                                    The officer was involved in - Model and manage the databases of Polling Personnels, EVM, Booths, and prepare various randomization report for assembly and municipal elections - Functioning as technical bridge in the district for every IT based Issue/problem in order to provide a situation- effective, cost- effective and innovative solution in the implementation of all e- Governance projects in the district. - Did requirement analysis in the development of a website for navigating wells and ponds in the district under Jal Jeewan Hariyali scheme  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28d44ab1-6e41-4324-ad73-cdcdd59c6399\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>level_0</th>\n",
              "      <th>index</th>\n",
              "      <th>content</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Innovative impacts of Chief Minister's Relief Fund application developed for Chief Minister's Office, RTI Online application, RTI Portal forGovernment of Maharashtra: Bilingual application in open source technology. Work flow based ICT solution- Ease in decision making through proper monitoring- Citizen centric services are easily accessible to common citizens- User friendly application- Role based application processing- Reduction in human interferences- Regular decisions and calculations are inbuilt in the application so that they are devoid of human error. Yield of best practices and te...</td>\n",
              "      <td>The officer was involved in - Development and implementation of Chief Minister's Relief Fund application, RTI Online application, RTI Portal, SIMNIC and Credit Sales - Product enhancement for CMRF project - Development of Bilingual, responsive application in open source technology. - Management on Servers Web and DB with backup mechanism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1. Chief Ministers Relief Fund Application- Requirement analysis, Designing and Development and security auditing and Maintenance of Chief Ministers Relief Fund web based Bilingual Application for Chief Ministers Office, Government of Maharashtra using Open source technology in MVC model (Platform: Java, Struts2,PostgreSQL)- For this entire SDLC is followed and with special emphasis on users requirement specifications. Developed modules consisting of Citizen Centric Services like online donation and online application submission, Payment verification, Receipt generation, Enquiry services u...</td>\n",
              "      <td>The officer was involved in - Requirement analysis, Designing and Development and security auditing and Maintenance of web based Chief Ministers Relief Fund project - Bilingual Application for Chief Ministers Office, using Open source technology in MVC model (Platform:Java, Struts2, PostgreSQL) - Citizen Centric Services like online donation and online application submission, Payment verification, Receipt generation, Enquiry services using Payment Gateway with SMS, Email integration. - Implementation of RTI online and RTI Portal - Coordination in Implementation, Training and Support of Mah...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>- Chief Ministers Relief Fund application enabled citizens to donate money to Chief Ministers office from any geographical location using online payment gateway with ease, with a feature of online receipt generation which citizen can use for Income tax ex</td>\n",
              "      <td>The officer was involved in - Design, development and implementation of ief Ministers Relief Fund application with integration of payment gateway, SMS and e-Mail. - Implementation of RTI Online application with payment gateway integration - Writing Shell Scripts and cron for service availability - Credit and Sales monitoring application - Development of Multidepartment projects locally in Open Source along with server administration</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>The technical coordination, the IT support to the various user department has always been done in the situation effective and efficacious manner. In order to make the district digitally efficacious and well benefited of the digital india schemes and vaious e-governance projects the implementation of the project were done timely and to the proper stake holders of a project. The various offices of the government in the district like transport,registry,mining offices were made cashless yielding a very transparent and corruption free environment. The BCC course and Tally course were tagged wit...</td>\n",
              "      <td>The Officer was involved - Implementation of digital india schemes and vaious e- governance projects - Migrated the district website under S3WaaS framework - Providing technical support for all the elections in the district - Implemented PMKISAN and CMKAY project in the district - Tested and implemented different software like EPMIS, Food DBT Portal, Force Deployment Portal, Covid registration portal, AApda Sampoorti portal etc..</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>To analyse a technical matter and to provide its systematic, IT based situation-effective solution to the user department in the district. To model and manage the databases of Polling Personnels,EVM,Booths, and prepare various randomization reports in the LITTIPARA assembly bye-election 2017. To render the technical coordination for an effective IT based solution in various e-governance projects of state and central level. To work as a technical IT support adviser to DC of the district. To impart training on various e-governance project to the respective user departments. To solve the tech...</td>\n",
              "      <td>The officer was involved in - Model and manage the databases of Polling Personnels, EVM, Booths, and prepare various randomization report for assembly and municipal elections - Functioning as technical bridge in the district for every IT based Issue/problem in order to provide a situation- effective, cost- effective and innovative solution in the implementation of all e- Governance projects in the district. - Did requirement analysis in the development of a website for navigating wells and ponds in the district under Jal Jeewan Hariyali scheme</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28d44ab1-6e41-4324-ad73-cdcdd59c6399')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-28d44ab1-6e41-4324-ad73-cdcdd59c6399 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-28d44ab1-6e41-4324-ad73-cdcdd59c6399');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Select only part of it (makes testing faster)\n",
        "articles = df"
      ],
      "metadata": {
        "id": "9SYlYkQPre6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "articles"
      ],
      "metadata": {
        "id": "ijFWZOSdFuYX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ced796c0-25a6-497f-d98f-cfaa013fc86e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    level_0  index  \\\n",
              "0         0      1   \n",
              "1         1      2   \n",
              "2         2      3   \n",
              "3         3      4   \n",
              "4         4      5   \n",
              "5         5      6   \n",
              "6         6      7   \n",
              "7         7      8   \n",
              "8         8      9   \n",
              "9         9     10   \n",
              "10       10     11   \n",
              "11       11     12   \n",
              "12       12     15   \n",
              "13       13     18   \n",
              "14       14     19   \n",
              "15       15     21   \n",
              "16       16     22   \n",
              "17       17     23   \n",
              "18       18     26   \n",
              "19       19     27   \n",
              "20       20     28   \n",
              "21       21     29   \n",
              "22       22     30   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    content  \\\n",
              "0   Innovative impacts of Chief Minister's Relief Fund application developed for Chief Minister's Office, RTI Online application, RTI Portal forGovernment of Maharashtra: Bilingual application in open source technology. Work flow based ICT solution- Ease in decision making through proper monitoring- Citizen centric services are easily accessible to common citizens- User friendly application- Role based application processing- Reduction in human interferences- Regular decisions and calculations are inbuilt in the application so that they are devoid of human error. Yield of best practices and te...   \n",
              "1   1. Chief Ministers Relief Fund Application- Requirement analysis, Designing and Development and security auditing and Maintenance of Chief Ministers Relief Fund web based Bilingual Application for Chief Ministers Office, Government of Maharashtra using Open source technology in MVC model (Platform: Java, Struts2,PostgreSQL)- For this entire SDLC is followed and with special emphasis on users requirement specifications. Developed modules consisting of Citizen Centric Services like online donation and online application submission, Payment verification, Receipt generation, Enquiry services u...   \n",
              "2                                                                                                                                                                                                                                                                                                                                                           - Chief Ministers Relief Fund application enabled citizens to donate money to Chief Ministers office from any geographical location using online payment gateway with ease, with a feature of online receipt generation which citizen can use for Income tax ex   \n",
              "3   The technical coordination, the IT support to the various user department has always been done in the situation effective and efficacious manner. In order to make the district digitally efficacious and well benefited of the digital india schemes and vaious e-governance projects the implementation of the project were done timely and to the proper stake holders of a project. The various offices of the government in the district like transport,registry,mining offices were made cashless yielding a very transparent and corruption free environment. The BCC course and Tally course were tagged wit...   \n",
              "4   To analyse a technical matter and to provide its systematic, IT based situation-effective solution to the user department in the district. To model and manage the databases of Polling Personnels,EVM,Booths, and prepare various randomization reports in the LITTIPARA assembly bye-election 2017. To render the technical coordination for an effective IT based solution in various e-governance projects of state and central level. To work as a technical IT support adviser to DC of the district. To impart training on various e-governance project to the respective user departments. To solve the tech...   \n",
              "5   While being posted in NIC Jharkhand State Unit,Ranchi i was involved in some critical projects like employment exchange, NGDRS,SPARROW etc. which has hugely transformed the end users' life . The unemployed youth is nowadays getting instant messages on hisher mobile for a rojgar mela or any other vacancy available in the employment exchange. Now a days IAS and IPS officers are filling their APAR online withing a time frame. The land registration has be completely transformed and become secure with proper land details pre-registration enqury etc. Ease of doing Business emerged through ICT ba...   \n",
              "6   The technical coordination, the IT support to the various user department has always been done in the situation effective and efficacious manner. In order to make the district digitally efficacious and well benefited of the digital india schemes and vaious e-governance projects the implementation of the project were done timely and to the proper stake holders of a project. The various offices of the government in the district like transport,registry,mining offices were made cashless yielding a very transparent and corruption free environment. The BCC course and Tally course were tagged wit...   \n",
              "7   To analyse a technical matter and to provide its systematic, IT based situation-effective solution to the user department in the district. To model and manage the databases of Polling Personnels,EVM,Booths, and prepare various randomization reports in the LITTIPARA assembly bye-election 2017. To render the technical coordination for an effective IT based solution in various e-governance projects of state and central level. To work as a technical IT support adviser to DC of the district. To impart training on various e-governance project to the respective user departments. To solve the tech...   \n",
              "8   While being posted in NIC Jharkhand State Unit,Ranchi i was involved in some critical projects like employment exchange, NGDRS,SPARROW etc. which has hugely transformed the end users' life . The unemployed youth is nowadays getting instant messages on hisher mobile for a rojgar mela or any other vacancy available in the employment exchange. Now a days IAS and IPS officers are filling their APAR online withing a time frame. The land registration has be completely transformed and become secure with proper land details pre-registration enqury etc. Ease of doing Business emerged through ICT ba...   \n",
              "9   The back bone of pfms is integration with external system. the exchange of data from external system is at real time basis. To achieve this goal it force me to innovate the easiest as well as secure way to exchange of data. myself being a part of integration team I develop sftp based integration method, windowweb service based integration method and package based integration method. all these three option make pfms easy to connect external system to exchange of data. the provided option they(external system) opt as per their infrastructure support. The back bone of pfms is integration with...   \n",
              "10  Being a System analyst I have been assigned project PFMS to analysis,design and lead a team of . net developer to provide financial solution to end user as well as ministry user. I have also been assigned to plan Data Base architecture for project PFMS, also I have been involved day to day activities of DBA such asoptimizing query,log shipping, schedule backup. I have also assigned to design an architecture (solution) to integrate with external system and PFMS-EIS integration. Being a System analyst I have been assigned project PFMS to analysis, design and lead a team of . net developer to...   \n",
              "11  Financial year 2016-2017 closing achieved successfully with 17000 DSC making thedisbursement of 20000 crore on 31 march. - Financial year 2016-2017 closing achieved successfully with 17000 DSC making thedisbursement of 20000 crore on 31 march. - Till august 2019 approx 30 crore ewaybill is generated with 15 lacks ewaybill daily basis. PFMS database is able to handle high concurrency load at the time of quarter end and financial year end. 49 crores beneficiaries have been registered for various DBT schemes. PFMS database is able to handle high concurrency load at the time of quarter end and...   \n",
              "12  Enhance and Redesigned the Budget preparation and printing module due Non-plan and Plan merger. Visualized real time position of budget with UDAY or without UDAY and Reduced Processing time. Set a procedure of Office and designation creation process for PD accountIntroduce the PD account Office ID and designation code. Made online and reduce time consuming for PD fund transfer sanction and PD opening sanction to reduced Paper work. Standardised the PD fund transfer sanction report and sanctionsImproved processes due to re-engineering of various legacy and existing processes that includes r...   \n",
              "13  Disaster Recovery site at NDC, Delhi can play crucial role if in case disaster scenario occur. Network Management System (NMS) has been configured on managed devices using agent process and being monitored by manager process. Data Centre Infrastructure Management (DCIM) tool and its integration with NMS (HP- Open View) and BMS (Centre Space) tools to have an overall idea of server farm like overall temperature, relative humidity, floor space, power consumption, cooling etc for optimal and efficient use of resources. 1. Data Centre Infrastructure Management (DCIM) tool and its integration w...   \n",
              "14  1. Developed Pratibedan Online, an online report return portal for report collection from different levels. The report is compiled and generated online at the District level. The special feature is that, the Blocks are able to update the figures in the same report, the log is maintained automatically so that each updation can be tracked. 2. Comparison Testing Analysis of Mid Day Meal Software, developed by Axis Bank Vs the software by ICICI Bank. 3. DPR prepared for ANPR and Speed Detection - The undersigned was requested to prepare a DPR for ANPR(Automatic Number Plate Recognition) and Sp...   \n",
              "15  1. Reduction in paperwork. Offices are converted to less-paper offices. 2. Improved communication3. Improved logistical support4. Improved efficiency by reducing the latency period5. Computerised databases and report generation has speeded the compliance to stakeholder for getting various reports and MIS6. Record Keeping and archiving has become easy and maintainable with no papers and in lesser space 1. DPR prepared for ANPR and Speed Detection - The undersigned was requested to prepare a DPR for ANPR(Automatic Number Plate Recognition) and Speed Detection of a particular vehicle in the N...   \n",
              "16  Have developed the Mailing Service that collects the summary report of each district and sends it to respective DCDRODIO. Relay Mail of NIC was used for this. Cleared the security audit of that service successfully. Security audit of WebHalris has passed phase 1 by ISMO and being processed by CDAC. Developed web api and web services that facilitates integration of ERegistraion and Revenue Courts system with various agencies for providing various services. These services are integrated with RAS, CSC, HEPC, SARAL and Umang. Enhanced LRDataService by adding several web methods. In addition to...   \n",
              "17  1. Development of statistical report for e-registration that shows complete picture of the stateselected district within a selected period to track performance of deed registration. 2. Integration of ERegistration with RAS, Umang and CSC. 3. Integration of Various services of RCCMS like Judgement, Case Status etc with Umang App. 4. Creation of Scheduled Mail Service that sends emails to various administrative officers in districts regarding performance of each tehsilsubtehsil. 5. Relocation of scanned registered deeds data to the new provisioned storage. 6. Development of services of Scann...   \n",
              "18                                                                                                                                                                                                                                                                                                                                                               - Involved in System Analysis, Process Modelling Design, Development and Implementation of various projects which include analysis and development of new applications, enhancement of existing modules, automation of existing manual processes, business   \n",
              "19                                                                                                                                                                                                                                                                                                                                                           - e-RCMS has been developed and implemented, work-flow based paperless system . Aadhar seeding has helped remove duplicate and bogus Rationcard as well as duplicate members resulting in more authentic and clean database. With more statistical and monitor   \n",
              "20  It is learned that Bio metric device like finger print scanner with resolution of less than 350 dpI is not spoofing proof. fake finger print can be use to hack the system but it is not possible if we use the Bio metric device which support more than 500 dpi resolution. The installation of RD(recognize device) Service would enable the white list of valid devices which helps in enhancement of security of AEBAS system. we have created and used self signed certificate in DBT Application. we adopted sha256RSA algorithm for certificate generation, using openSSL technology supported by XAMPP fram...   \n",
              "21  NIC DNH UT Centre is playing vital role in e-governance activity as well as Digital India' programme. Here in DNH UT, The NIC UT centre offers so many services to the various departments belong to DNH UT Administration and many centre govt offices. We offer wide range of e-solution like (Gepnic-eProcurement, Vahan, Sarathi, Land Records NLRMP, eTPDS. NIC Cloud - Meghraj Support, Web site hosting support, Video Conferencing services and many more. I have been involved in implementation and deployment of few projects like A) Gepnic- eProcurement. Imparted training on GEPNIC and DSC handling....   \n",
              "22  More than 2400 cr value of tenders had been published on GEPNIC Portal instance of DNH UT Administration in from last two year. GepNIC have saved more than 160 lakh rupee tender publishing charge, which DNH UT used to pay as tender publishing charges on Private portal. The Government e-Market System is being use by all departments of DNH UT Administration. it has become first choice to procure Goods which are require for office use. Using Dedicated GepNIC Instance,Administration of Dadra Nagar Haveli has been selected as One of the Best Performers amongst Union Territories based on electro...   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      title  \n",
              "0                                                                                                                                                                                                                                                                       The officer was involved in - Development and implementation of Chief Minister's Relief Fund application, RTI Online application, RTI Portal, SIMNIC and Credit Sales - Product enhancement for CMRF project - Development of Bilingual, responsive application in open source technology. - Management on Servers Web and DB with backup mechanism  \n",
              "1   The officer was involved in - Requirement analysis, Designing and Development and security auditing and Maintenance of web based Chief Ministers Relief Fund project - Bilingual Application for Chief Ministers Office, using Open source technology in MVC model (Platform:Java, Struts2, PostgreSQL) - Citizen Centric Services like online donation and online application submission, Payment verification, Receipt generation, Enquiry services using Payment Gateway with SMS, Email integration. - Implementation of RTI online and RTI Portal - Coordination in Implementation, Training and Support of Mah...  \n",
              "2                                                                                                                                                                      The officer was involved in - Design, development and implementation of ief Ministers Relief Fund application with integration of payment gateway, SMS and e-Mail. - Implementation of RTI Online application with payment gateway integration - Writing Shell Scripts and cron for service availability - Credit and Sales monitoring application - Development of Multidepartment projects locally in Open Source along with server administration  \n",
              "3                                                                                                                                                                         The Officer was involved - Implementation of digital india schemes and vaious e- governance projects - Migrated the district website under S3WaaS framework - Providing technical support for all the elections in the district - Implemented PMKISAN and CMKAY project in the district - Tested and implemented different software like EPMIS, Food DBT Portal, Force Deployment Portal, Covid registration portal, AApda Sampoorti portal etc..  \n",
              "4                                                     The officer was involved in - Model and manage the databases of Polling Personnels, EVM, Booths, and prepare various randomization report for assembly and municipal elections - Functioning as technical bridge in the district for every IT based Issue/problem in order to provide a situation- effective, cost- effective and innovative solution in the implementation of all e- Governance projects in the district. - Did requirement analysis in the development of a website for navigating wells and ponds in the district under Jal Jeewan Hariyali scheme  \n",
              "5                                                                                                                                                                              The officer was involved in - Modeling and managing the databases of Polling Personnel, EVM, Booths, and prepare various randomization reports in the assembly bye-election, Municipal Election 2018 and Panchayat By- Election 2018 - Providing technical coordination for an effective IT based solution in various e- governance projects of state and central level. - Development and migration of district website on S3WaaS platform.  \n",
              "6                                                                                                                                                                         The Officer was involved - Implementation of digital india schemes and vaious e- governance projects - Migrated the district website under S3WaaS framework - Providing technical support for all the elections in the district - Implemented PMKISAN and CMKAY project in the district - Tested and implemented different software like EPMIS, Food DBT Portal, Force Deployment Portal, Covid registration portal, AApda Sampoorti portal etc..  \n",
              "7                                                     The officer was involved in - Model and manage the databases of Polling Personnels, EVM, Booths, and prepare various randomization report for assembly and municipal elections - Functioning as technical bridge in the district for every IT based Issue/problem in order to provide a situation- effective, cost- effective and innovative solution in the implementation of all e- Governance projects in the district. - Did requirement analysis in the development of a website for navigating wells and ponds in the district under Jal Jeewan Hariyali scheme  \n",
              "8                                                                                                                                                                              The officer was involved in - Modeling and managing the databases of Polling Personnel, EVM, Booths, and prepare various randomization reports in the assembly bye-election, Municipal Election 2018 and Panchayat By- Election 2018 - Providing technical coordination for an effective IT based solution in various e- governance projects of state and central level. - Development and migration of district website on S3WaaS platform.  \n",
              "9                                                                                                          The officer was involved in - Usage of different data integration methods like SFTP based, windows services, SSIS packages, BizTalk services etc - Performance Tuning, automation of archival of data, job scheduling, backup of large databases and round the clock monitoring of database servers. - Handling large databases and its related challenges like concurrency, process load and management of sessions - Database sherding process and setup of Distributed Availability group for DR site replica  \n",
              "10               The officer was involved in - Plan Data Base architecture for project PFMS, also I have been involved day to day activities of DBA such as optimizing query, log shipping, schedule backup. - Design an architecture (solution) to integrate with external system and PFMS- EIS integration - Design a database architecture of eway bill system, which provides high availability tosystem as well as handle high concurrency. - Preparing archival policy of databases at Data Centres. - Identify the bottlenecks and built the capacity of database server to do 1 crore payment transactions in a day  \n",
              "11  The officer was involved in - As a Database Administrator in optimising queries, monitoring of database servers, scheduling backups and all housekeeping work related to the PFMS database management. - Integration of the NGO Darpan portal with PFMS and building validations on the PFMS application - Upgrading PFMS to Windows Server 2016 and SQL Server 2016, switching over the databases to Always ON availability groups, database architecture revamp, data archival. - Development of different modes through which external systems integrate viz. SFTP based integration, Windows/Web service based i...  \n",
              "12                                                                                      The officer was involved in - NIC Data quality Challenges 2020 and shortlisted in 2nd round - Performance fine tuning, testing and reviewing of code of land records database and Shalldarpan database. - Digital Signature in PD opening module, PD fund transfer, Re- appropriation module and BFC MoM - Organising the IMF on macro- eco analysis, forecasting and GPS Modified budget due to Non- Plan and Plan merger concept - Designed and developed new algorithms/functions for various process for gender budget concept.  \n",
              "13                                                                                                              The officer was involved in - Reviewing of audit reports, VAPT of servers, cloud solution implementation - Monitoring of Data Centre using R OBR- OMI tools of HP Open View. - Reviewing ISO documents like incident management, change management and problem management as well as various policy documents critical for the smooth functioning of data centre - Deployment of tools like DCIM, NMS and APM. - Migration activity and prepared revenue model for offering DC services from Data Center. -  \n",
              "14  The officer was involved in - Design, development and implementation of online report return portal (Pratibedan) for report collection from different levels - Comparison/ Testing/ Analysis of Mid Day Meal Software, developed by Axis Bank Vs the software by ICICI Bank - Preparation of DPR for launching Drone Services - Preparing the beneficiary database by merging RHS database of BPL families and NREGA database. - Development of Nadia Website in SWAAS framework - Development and implementation of Sikhashree application to maintain the records of scholarship provided to the school children b...  \n",
              "15                                                                                                                                                                                                                                                                                                                               The officers were involved in - Design, development, hosting and augmentation of portals like District Portal, Pratibedan online etc - Development, implementation and support of eChallan project - Integration of Darpan portal with eChallan via REST API, for sharing statistical data  \n",
              "16                                                              The officer was involved in - Integrated ERegistration with RAS, Umang and CSC, RCCMS with Umang App - Developed the portal for providing combined search page for properties in rural, ULB and HUDA under EoDB - Development of GovLand Portal to facilitate the departments and government know the status of their properties. - Developed the khasra gridawari and fard badar module of WEB- HALRIS - Involved in the creation of e- Services of Revenue Department on SARAL platform. - Developed REST- API for integration with the Soil Health card.  \n",
              "17                                                                                                                                                                                                                                                                                                                                                                                                                  The officer was involved in - Integration of ERegistration with RAS, Umang and CSC. - Seamless integration of Haris and Halris system. - SARAL Haryana: Service Online based platform for Haryana state  \n",
              "18                                                                                                                                                                                           The officer was involved in - System Analysis, Process Modelling Design, Development and Implementation of PDS application - Using Free and Open Source Software technologies to overcome challenges for eGov applications - Providing an algorithmic solution based on software to automate transferring of subsidy amount of PDS DBT, in- line with \"PAHAL\" yojna, lifted from HHD directly into beneficiaries bank accounts  \n",
              "19  The officer was involved in - Development and implementation of work- flow based 7 major modules of PDS viz. e-RCMS, AbPDS, AAHAR, K-Oil DBT, SCM etc., - Hosted all PDS application in State Data Centre - Customization, development and implementation of PTG DAKIA - Database Administrator support to PDS Centralized Database - Design, development and implementation of backup and archival policy for the PDS master and slave database - Technical support and co- ordination for payment of PDS- DBT through PFMS. - Performance fine tuning of PDS database and application server. - Implementation of ...  \n",
              "20  The officer was involved in - Development of a conversational AI Base chatbot assistant using rasa framework - a prototype of FAQ Base chatbot during pandemic period - Development and implementation of Randomization software under .net framework with OWASP compliance and multifactor authentication - Implementation of Gepnic, Vahan, Sarathi, NLRMP, Aatithi Darpan, Rojgar setu, Yatra setu and eTPDS in the UT Administration - Providing technical support for the cloud management, website hosting and VC sessions. - Providing training on DSC handling as part of GEPNIC implementation - Promotion ...  \n",
              "21                                                                                                                                                                                                      The officer was involved in the - Development and implementation of Randomization application, cVigil App, Voter Helpline App and PwD app for the election process - Implementation of GEPNIC and DSC handling. - Promotion of e-Mail and VC solutions in the UT - Providing technical support for the implementation of AEBAS, SPARROW, National Scholarship Portal and Public Financial Management System for DBT  \n",
              "22                                                                                         The officer was involved in - Developing and implementing the Randomization software, cVigil, Voter Helpline and PwD app for the elections. - Integration of FAQ base Chat Bot assistant with web application and hosting of RASA action server and NLU - Implementing Gepnic, Vahan, Sarathi, Land Records NLRMP, eTPDS, AEBAS, SPARROW, National Scholarship Portal in the UT - Providing technical support for Cloud Management, Web site hosting support and VC services. - Providing implementation support for GEM portal.  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d156e880-5a0d-4a6e-89a4-34ece0fcd8dd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>level_0</th>\n",
              "      <th>index</th>\n",
              "      <th>content</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Innovative impacts of Chief Minister's Relief Fund application developed for Chief Minister's Office, RTI Online application, RTI Portal forGovernment of Maharashtra: Bilingual application in open source technology. Work flow based ICT solution- Ease in decision making through proper monitoring- Citizen centric services are easily accessible to common citizens- User friendly application- Role based application processing- Reduction in human interferences- Regular decisions and calculations are inbuilt in the application so that they are devoid of human error. Yield of best practices and te...</td>\n",
              "      <td>The officer was involved in - Development and implementation of Chief Minister's Relief Fund application, RTI Online application, RTI Portal, SIMNIC and Credit Sales - Product enhancement for CMRF project - Development of Bilingual, responsive application in open source technology. - Management on Servers Web and DB with backup mechanism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1. Chief Ministers Relief Fund Application- Requirement analysis, Designing and Development and security auditing and Maintenance of Chief Ministers Relief Fund web based Bilingual Application for Chief Ministers Office, Government of Maharashtra using Open source technology in MVC model (Platform: Java, Struts2,PostgreSQL)- For this entire SDLC is followed and with special emphasis on users requirement specifications. Developed modules consisting of Citizen Centric Services like online donation and online application submission, Payment verification, Receipt generation, Enquiry services u...</td>\n",
              "      <td>The officer was involved in - Requirement analysis, Designing and Development and security auditing and Maintenance of web based Chief Ministers Relief Fund project - Bilingual Application for Chief Ministers Office, using Open source technology in MVC model (Platform:Java, Struts2, PostgreSQL) - Citizen Centric Services like online donation and online application submission, Payment verification, Receipt generation, Enquiry services using Payment Gateway with SMS, Email integration. - Implementation of RTI online and RTI Portal - Coordination in Implementation, Training and Support of Mah...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>- Chief Ministers Relief Fund application enabled citizens to donate money to Chief Ministers office from any geographical location using online payment gateway with ease, with a feature of online receipt generation which citizen can use for Income tax ex</td>\n",
              "      <td>The officer was involved in - Design, development and implementation of ief Ministers Relief Fund application with integration of payment gateway, SMS and e-Mail. - Implementation of RTI Online application with payment gateway integration - Writing Shell Scripts and cron for service availability - Credit and Sales monitoring application - Development of Multidepartment projects locally in Open Source along with server administration</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>The technical coordination, the IT support to the various user department has always been done in the situation effective and efficacious manner. In order to make the district digitally efficacious and well benefited of the digital india schemes and vaious e-governance projects the implementation of the project were done timely and to the proper stake holders of a project. The various offices of the government in the district like transport,registry,mining offices were made cashless yielding a very transparent and corruption free environment. The BCC course and Tally course were tagged wit...</td>\n",
              "      <td>The Officer was involved - Implementation of digital india schemes and vaious e- governance projects - Migrated the district website under S3WaaS framework - Providing technical support for all the elections in the district - Implemented PMKISAN and CMKAY project in the district - Tested and implemented different software like EPMIS, Food DBT Portal, Force Deployment Portal, Covid registration portal, AApda Sampoorti portal etc..</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>To analyse a technical matter and to provide its systematic, IT based situation-effective solution to the user department in the district. To model and manage the databases of Polling Personnels,EVM,Booths, and prepare various randomization reports in the LITTIPARA assembly bye-election 2017. To render the technical coordination for an effective IT based solution in various e-governance projects of state and central level. To work as a technical IT support adviser to DC of the district. To impart training on various e-governance project to the respective user departments. To solve the tech...</td>\n",
              "      <td>The officer was involved in - Model and manage the databases of Polling Personnels, EVM, Booths, and prepare various randomization report for assembly and municipal elections - Functioning as technical bridge in the district for every IT based Issue/problem in order to provide a situation- effective, cost- effective and innovative solution in the implementation of all e- Governance projects in the district. - Did requirement analysis in the development of a website for navigating wells and ponds in the district under Jal Jeewan Hariyali scheme</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>While being posted in NIC Jharkhand State Unit,Ranchi i was involved in some critical projects like employment exchange, NGDRS,SPARROW etc. which has hugely transformed the end users' life . The unemployed youth is nowadays getting instant messages on hisher mobile for a rojgar mela or any other vacancy available in the employment exchange. Now a days IAS and IPS officers are filling their APAR online withing a time frame. The land registration has be completely transformed and become secure with proper land details pre-registration enqury etc. Ease of doing Business emerged through ICT ba...</td>\n",
              "      <td>The officer was involved in - Modeling and managing the databases of Polling Personnel, EVM, Booths, and prepare various randomization reports in the assembly bye-election, Municipal Election 2018 and Panchayat By- Election 2018 - Providing technical coordination for an effective IT based solution in various e- governance projects of state and central level. - Development and migration of district website on S3WaaS platform.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>The technical coordination, the IT support to the various user department has always been done in the situation effective and efficacious manner. In order to make the district digitally efficacious and well benefited of the digital india schemes and vaious e-governance projects the implementation of the project were done timely and to the proper stake holders of a project. The various offices of the government in the district like transport,registry,mining offices were made cashless yielding a very transparent and corruption free environment. The BCC course and Tally course were tagged wit...</td>\n",
              "      <td>The Officer was involved - Implementation of digital india schemes and vaious e- governance projects - Migrated the district website under S3WaaS framework - Providing technical support for all the elections in the district - Implemented PMKISAN and CMKAY project in the district - Tested and implemented different software like EPMIS, Food DBT Portal, Force Deployment Portal, Covid registration portal, AApda Sampoorti portal etc..</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>To analyse a technical matter and to provide its systematic, IT based situation-effective solution to the user department in the district. To model and manage the databases of Polling Personnels,EVM,Booths, and prepare various randomization reports in the LITTIPARA assembly bye-election 2017. To render the technical coordination for an effective IT based solution in various e-governance projects of state and central level. To work as a technical IT support adviser to DC of the district. To impart training on various e-governance project to the respective user departments. To solve the tech...</td>\n",
              "      <td>The officer was involved in - Model and manage the databases of Polling Personnels, EVM, Booths, and prepare various randomization report for assembly and municipal elections - Functioning as technical bridge in the district for every IT based Issue/problem in order to provide a situation- effective, cost- effective and innovative solution in the implementation of all e- Governance projects in the district. - Did requirement analysis in the development of a website for navigating wells and ponds in the district under Jal Jeewan Hariyali scheme</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>While being posted in NIC Jharkhand State Unit,Ranchi i was involved in some critical projects like employment exchange, NGDRS,SPARROW etc. which has hugely transformed the end users' life . The unemployed youth is nowadays getting instant messages on hisher mobile for a rojgar mela or any other vacancy available in the employment exchange. Now a days IAS and IPS officers are filling their APAR online withing a time frame. The land registration has be completely transformed and become secure with proper land details pre-registration enqury etc. Ease of doing Business emerged through ICT ba...</td>\n",
              "      <td>The officer was involved in - Modeling and managing the databases of Polling Personnel, EVM, Booths, and prepare various randomization reports in the assembly bye-election, Municipal Election 2018 and Panchayat By- Election 2018 - Providing technical coordination for an effective IT based solution in various e- governance projects of state and central level. - Development and migration of district website on S3WaaS platform.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>The back bone of pfms is integration with external system. the exchange of data from external system is at real time basis. To achieve this goal it force me to innovate the easiest as well as secure way to exchange of data. myself being a part of integration team I develop sftp based integration method, windowweb service based integration method and package based integration method. all these three option make pfms easy to connect external system to exchange of data. the provided option they(external system) opt as per their infrastructure support. The back bone of pfms is integration with...</td>\n",
              "      <td>The officer was involved in - Usage of different data integration methods like SFTP based, windows services, SSIS packages, BizTalk services etc - Performance Tuning, automation of archival of data, job scheduling, backup of large databases and round the clock monitoring of database servers. - Handling large databases and its related challenges like concurrency, process load and management of sessions - Database sherding process and setup of Distributed Availability group for DR site replica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>Being a System analyst I have been assigned project PFMS to analysis,design and lead a team of . net developer to provide financial solution to end user as well as ministry user. I have also been assigned to plan Data Base architecture for project PFMS, also I have been involved day to day activities of DBA such asoptimizing query,log shipping, schedule backup. I have also assigned to design an architecture (solution) to integrate with external system and PFMS-EIS integration. Being a System analyst I have been assigned project PFMS to analysis, design and lead a team of . net developer to...</td>\n",
              "      <td>The officer was involved in - Plan Data Base architecture for project PFMS, also I have been involved day to day activities of DBA such as optimizing query, log shipping, schedule backup. - Design an architecture (solution) to integrate with external system and PFMS- EIS integration - Design a database architecture of eway bill system, which provides high availability tosystem as well as handle high concurrency. - Preparing archival policy of databases at Data Centres. - Identify the bottlenecks and built the capacity of database server to do 1 crore payment transactions in a day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>Financial year 2016-2017 closing achieved successfully with 17000 DSC making thedisbursement of 20000 crore on 31 march. - Financial year 2016-2017 closing achieved successfully with 17000 DSC making thedisbursement of 20000 crore on 31 march. - Till august 2019 approx 30 crore ewaybill is generated with 15 lacks ewaybill daily basis. PFMS database is able to handle high concurrency load at the time of quarter end and financial year end. 49 crores beneficiaries have been registered for various DBT schemes. PFMS database is able to handle high concurrency load at the time of quarter end and...</td>\n",
              "      <td>The officer was involved in - As a Database Administrator in optimising queries, monitoring of database servers, scheduling backups and all housekeeping work related to the PFMS database management. - Integration of the NGO Darpan portal with PFMS and building validations on the PFMS application - Upgrading PFMS to Windows Server 2016 and SQL Server 2016, switching over the databases to Always ON availability groups, database architecture revamp, data archival. - Development of different modes through which external systems integrate viz. SFTP based integration, Windows/Web service based i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>15</td>\n",
              "      <td>Enhance and Redesigned the Budget preparation and printing module due Non-plan and Plan merger. Visualized real time position of budget with UDAY or without UDAY and Reduced Processing time. Set a procedure of Office and designation creation process for PD accountIntroduce the PD account Office ID and designation code. Made online and reduce time consuming for PD fund transfer sanction and PD opening sanction to reduced Paper work. Standardised the PD fund transfer sanction report and sanctionsImproved processes due to re-engineering of various legacy and existing processes that includes r...</td>\n",
              "      <td>The officer was involved in - NIC Data quality Challenges 2020 and shortlisted in 2nd round - Performance fine tuning, testing and reviewing of code of land records database and Shalldarpan database. - Digital Signature in PD opening module, PD fund transfer, Re- appropriation module and BFC MoM - Organising the IMF on macro- eco analysis, forecasting and GPS Modified budget due to Non- Plan and Plan merger concept - Designed and developed new algorithms/functions for various process for gender budget concept.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>18</td>\n",
              "      <td>Disaster Recovery site at NDC, Delhi can play crucial role if in case disaster scenario occur. Network Management System (NMS) has been configured on managed devices using agent process and being monitored by manager process. Data Centre Infrastructure Management (DCIM) tool and its integration with NMS (HP- Open View) and BMS (Centre Space) tools to have an overall idea of server farm like overall temperature, relative humidity, floor space, power consumption, cooling etc for optimal and efficient use of resources. 1. Data Centre Infrastructure Management (DCIM) tool and its integration w...</td>\n",
              "      <td>The officer was involved in - Reviewing of audit reports, VAPT of servers, cloud solution implementation - Monitoring of Data Centre using R OBR- OMI tools of HP Open View. - Reviewing ISO documents like incident management, change management and problem management as well as various policy documents critical for the smooth functioning of data centre - Deployment of tools like DCIM, NMS and APM. - Migration activity and prepared revenue model for offering DC services from Data Center. -</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>19</td>\n",
              "      <td>1. Developed Pratibedan Online, an online report return portal for report collection from different levels. The report is compiled and generated online at the District level. The special feature is that, the Blocks are able to update the figures in the same report, the log is maintained automatically so that each updation can be tracked. 2. Comparison Testing Analysis of Mid Day Meal Software, developed by Axis Bank Vs the software by ICICI Bank. 3. DPR prepared for ANPR and Speed Detection - The undersigned was requested to prepare a DPR for ANPR(Automatic Number Plate Recognition) and Sp...</td>\n",
              "      <td>The officer was involved in - Design, development and implementation of online report return portal (Pratibedan) for report collection from different levels - Comparison/ Testing/ Analysis of Mid Day Meal Software, developed by Axis Bank Vs the software by ICICI Bank - Preparation of DPR for launching Drone Services - Preparing the beneficiary database by merging RHS database of BPL families and NREGA database. - Development of Nadia Website in SWAAS framework - Development and implementation of Sikhashree application to maintain the records of scholarship provided to the school children b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>21</td>\n",
              "      <td>1. Reduction in paperwork. Offices are converted to less-paper offices. 2. Improved communication3. Improved logistical support4. Improved efficiency by reducing the latency period5. Computerised databases and report generation has speeded the compliance to stakeholder for getting various reports and MIS6. Record Keeping and archiving has become easy and maintainable with no papers and in lesser space 1. DPR prepared for ANPR and Speed Detection - The undersigned was requested to prepare a DPR for ANPR(Automatic Number Plate Recognition) and Speed Detection of a particular vehicle in the N...</td>\n",
              "      <td>The officers were involved in - Design, development, hosting and augmentation of portals like District Portal, Pratibedan online etc - Development, implementation and support of eChallan project - Integration of Darpan portal with eChallan via REST API, for sharing statistical data</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>22</td>\n",
              "      <td>Have developed the Mailing Service that collects the summary report of each district and sends it to respective DCDRODIO. Relay Mail of NIC was used for this. Cleared the security audit of that service successfully. Security audit of WebHalris has passed phase 1 by ISMO and being processed by CDAC. Developed web api and web services that facilitates integration of ERegistraion and Revenue Courts system with various agencies for providing various services. These services are integrated with RAS, CSC, HEPC, SARAL and Umang. Enhanced LRDataService by adding several web methods. In addition to...</td>\n",
              "      <td>The officer was involved in - Integrated ERegistration with RAS, Umang and CSC, RCCMS with Umang App - Developed the portal for providing combined search page for properties in rural, ULB and HUDA under EoDB - Development of GovLand Portal to facilitate the departments and government know the status of their properties. - Developed the khasra gridawari and fard badar module of WEB- HALRIS - Involved in the creation of e- Services of Revenue Department on SARAL platform. - Developed REST- API for integration with the Soil Health card.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>23</td>\n",
              "      <td>1. Development of statistical report for e-registration that shows complete picture of the stateselected district within a selected period to track performance of deed registration. 2. Integration of ERegistration with RAS, Umang and CSC. 3. Integration of Various services of RCCMS like Judgement, Case Status etc with Umang App. 4. Creation of Scheduled Mail Service that sends emails to various administrative officers in districts regarding performance of each tehsilsubtehsil. 5. Relocation of scanned registered deeds data to the new provisioned storage. 6. Development of services of Scann...</td>\n",
              "      <td>The officer was involved in - Integration of ERegistration with RAS, Umang and CSC. - Seamless integration of Haris and Halris system. - SARAL Haryana: Service Online based platform for Haryana state</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>26</td>\n",
              "      <td>- Involved in System Analysis, Process Modelling Design, Development and Implementation of various projects which include analysis and development of new applications, enhancement of existing modules, automation of existing manual processes, business</td>\n",
              "      <td>The officer was involved in - System Analysis, Process Modelling Design, Development and Implementation of PDS application - Using Free and Open Source Software technologies to overcome challenges for eGov applications - Providing an algorithmic solution based on software to automate transferring of subsidy amount of PDS DBT, in- line with \"PAHAL\" yojna, lifted from HHD directly into beneficiaries bank accounts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>27</td>\n",
              "      <td>- e-RCMS has been developed and implemented, work-flow based paperless system . Aadhar seeding has helped remove duplicate and bogus Rationcard as well as duplicate members resulting in more authentic and clean database. With more statistical and monitor</td>\n",
              "      <td>The officer was involved in - Development and implementation of work- flow based 7 major modules of PDS viz. e-RCMS, AbPDS, AAHAR, K-Oil DBT, SCM etc., - Hosted all PDS application in State Data Centre - Customization, development and implementation of PTG DAKIA - Database Administrator support to PDS Centralized Database - Design, development and implementation of backup and archival policy for the PDS master and slave database - Technical support and co- ordination for payment of PDS- DBT through PFMS. - Performance fine tuning of PDS database and application server. - Implementation of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>28</td>\n",
              "      <td>It is learned that Bio metric device like finger print scanner with resolution of less than 350 dpI is not spoofing proof. fake finger print can be use to hack the system but it is not possible if we use the Bio metric device which support more than 500 dpi resolution. The installation of RD(recognize device) Service would enable the white list of valid devices which helps in enhancement of security of AEBAS system. we have created and used self signed certificate in DBT Application. we adopted sha256RSA algorithm for certificate generation, using openSSL technology supported by XAMPP fram...</td>\n",
              "      <td>The officer was involved in - Development of a conversational AI Base chatbot assistant using rasa framework - a prototype of FAQ Base chatbot during pandemic period - Development and implementation of Randomization software under .net framework with OWASP compliance and multifactor authentication - Implementation of Gepnic, Vahan, Sarathi, NLRMP, Aatithi Darpan, Rojgar setu, Yatra setu and eTPDS in the UT Administration - Providing technical support for the cloud management, website hosting and VC sessions. - Providing training on DSC handling as part of GEPNIC implementation - Promotion ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>29</td>\n",
              "      <td>NIC DNH UT Centre is playing vital role in e-governance activity as well as Digital India' programme. Here in DNH UT, The NIC UT centre offers so many services to the various departments belong to DNH UT Administration and many centre govt offices. We offer wide range of e-solution like (Gepnic-eProcurement, Vahan, Sarathi, Land Records NLRMP, eTPDS. NIC Cloud - Meghraj Support, Web site hosting support, Video Conferencing services and many more. I have been involved in implementation and deployment of few projects like A) Gepnic- eProcurement. Imparted training on GEPNIC and DSC handling....</td>\n",
              "      <td>The officer was involved in the - Development and implementation of Randomization application, cVigil App, Voter Helpline App and PwD app for the election process - Implementation of GEPNIC and DSC handling. - Promotion of e-Mail and VC solutions in the UT - Providing technical support for the implementation of AEBAS, SPARROW, National Scholarship Portal and Public Financial Management System for DBT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>30</td>\n",
              "      <td>More than 2400 cr value of tenders had been published on GEPNIC Portal instance of DNH UT Administration in from last two year. GepNIC have saved more than 160 lakh rupee tender publishing charge, which DNH UT used to pay as tender publishing charges on Private portal. The Government e-Market System is being use by all departments of DNH UT Administration. it has become first choice to procure Goods which are require for office use. Using Dedicated GepNIC Instance,Administration of Dadra Nagar Haveli has been selected as One of the Best Performers amongst Union Territories based on electro...</td>\n",
              "      <td>The officer was involved in - Developing and implementing the Randomization software, cVigil, Voter Helpline and PwD app for the elections. - Integration of FAQ base Chat Bot assistant with web application and hosting of RASA action server and NLU - Implementing Gepnic, Vahan, Sarathi, Land Records NLRMP, eTPDS, AEBAS, SPARROW, National Scholarship Portal in the UT - Providing technical support for Cloud Management, Web site hosting support and VC services. - Providing implementation support for GEM portal.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d156e880-5a0d-4a6e-89a4-34ece0fcd8dd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d156e880-5a0d-4a6e-89a4-34ece0fcd8dd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d156e880-5a0d-4a6e-89a4-34ece0fcd8dd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Text and Set Up Data"
      ],
      "metadata": {
        "id": "mkGf-y4JrlVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model_name = \"facebook/bart-large-cnn\"\n",
        "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, \n",
        "                                                                  model_cls=BartForConditionalGeneration) #replaced BLURR to BLURR_MODEL_HELPER\n",
        "hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)"
      ],
      "metadata": {
        "id": "dbf_SqcjrjcO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278,
          "referenced_widgets": [
            "76dd073247584b3eb0267f92842bc089",
            "135e3af585954a0e998af97b0033201e",
            "481057248883430ebdd3c21f60e4f1e7",
            "ca394c476c8943388f07a9991d4b58ee",
            "9704e51829b640319c7228e18d32cef3",
            "98dc53c9dabd4c81a2122e188720dc9b",
            "900cd2d148b941f48f19de5a38a0e83b",
            "51c05828cb684a1cb58ee4313d1d07f9",
            "1576a98e8db743bca6ad7d9efe30ea40",
            "d0eedfddf45b42dc92c0314434852e2a",
            "fcb9cef9e609465b9024c1c5aa9859fc",
            "7308d656bd394e77877ec33b48e5a58f",
            "24a62e8e6aaf45beac522bf34d818a68",
            "e66b821289674e95aabcd7d35e680734",
            "25cc159161e84009b597486db7cd1669",
            "09d8e58302984138b0904ccde87392a2",
            "d91da1a77b984acfbb196054825f7006",
            "fd3e00144ce6423da7b934e557ce1cc9",
            "2a5fdda1707046558779782c16400b0a",
            "b9f155cc9e034bc4b9e79c942cf83b16",
            "db40eca93af34e8490b62069bd2b4175",
            "bb8ae03cbae04aa2946067760ce7222e",
            "f2b20c9457194afbb06d5bde4b874912",
            "8c7ea6ce794442f5a761cb97a7573c96",
            "82ec7a40c0b6429884e6c08eab84bcab",
            "804d2b456e0647d6bdd7deba7ab9f0f0",
            "5b3e9aa395874d3b90330a610b6660b6",
            "ff0df9e13ef94f319ccceb19366390a8",
            "7064502c8e444a198854c7d4361e26b0",
            "37df01ee202247c18f03d5befec00be2",
            "76553477e29b4e248871d8b01df28a44",
            "8d61cfb7014e4fb6825140d50f544b97",
            "7cd6b3f46ec04755aed2d855c3f8a393",
            "46aabd91a13245b9aa3a10ec91631ef4",
            "85a2db97f1a7483e90f10d6a8a09b0cc",
            "e8021aa01e76437eaf1a7f79b5917b15",
            "0792f72f508a42c7a13e616591f00b5e",
            "13e596f990bc45d19f42771f20af39fd",
            "7bdae288ed744408b4106093bb2dd429",
            "30a97447762f4e51a57bc8e8fdb639fb",
            "da24ebde217548acb8f3b92ed19a0354",
            "06f0075af24f4886a5ab4b9097a5f643",
            "c40140d90b7c428cb95fe8fad70bbb8f",
            "c31c387e26b942f2bc8ff644ac7cbc51",
            "87d3bfaada9c4719be91892c925111a8",
            "4382889c8b694ecda362b4e54cf15bdf",
            "26b0e0d59e67402caa4a35554902b194",
            "96b1760c6eb84f88a0e7deb8683ea4e6",
            "ca90f4873f4244f1a650afe22e2e4d33",
            "6cd596d6de06431d83744bb7f8cf51e6",
            "dbdb08dbeeec4ac1be6d76e5540a2b07",
            "45cee4423c084ccfadae7479b4ed5171",
            "68a8f9156f1947ebbec1dbedd54a2f24",
            "2c1323a79fda43c88136929c435a0dc0",
            "fc51e3bbb0444d989f656ef141e0e8e1",
            "fcac146f119c483cbf827f0e39a6cf23",
            "1a07861b41aa45a0b50e846b2624cfeb",
            "d5223ffc030345099684bf733e8eb2a7",
            "cffba9b60e63410eaf183e06f549aba4",
            "b81ca28e0d7c4bf1a304710f1dad156d",
            "9edaf4931d384f8ca027416f942ef4c4",
            "596a6de88e7b402c96bd1f9e3bb08180",
            "5598f9aedf954a769164b6274ad48907",
            "cc4aa627f5ee48fba711fc6df75d55a8",
            "ed296bac50614b00b2dbf61400b2b5a7",
            "9e0459d7169a4299b070e97c555665cb"
          ]
        },
        "outputId": "a6ba7408-f5e4-4fcb-babc-9b02092e89ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76dd073247584b3eb0267f92842bc089"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7308d656bd394e77877ec33b48e5a58f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2b20c9457194afbb06d5bde4b874912"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46aabd91a13245b9aa3a10ec91631ef4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87d3bfaada9c4719be91892c925111a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fcac146f119c483cbf827f0e39a6cf23"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('bart',\n",
              " transformers.models.bart.configuration_bart.BartConfig,\n",
              " transformers.models.bart.tokenization_bart_fast.BartTokenizerFast,\n",
              " transformers.models.bart.modeling_bart.BartForConditionalGeneration)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hf_batch_tfm = HF_Seq2SeqBeforeBatchTransform(hf_arch, hf_config, hf_tokenizer, hf_model, task='summarization',\n",
        "text_gen_kwargs={'max_length': 250,\n",
        " 'min_length': 50,\n",
        " 'do_sample': False,\n",
        " 'early_stopping': False,\n",
        " 'num_beams': 4,\n",
        " 'temperature': 1.0,\n",
        " 'top_k': 50,\n",
        " 'top_p': 1.0,\n",
        " 'repetition_penalty': 1.0,\n",
        " 'bad_words_ids': None,\n",
        " 'bos_token_id': 0,\n",
        " 'pad_token_id': 1,\n",
        " 'eos_token_id': 2,\n",
        " 'length_penalty': 2.0,\n",
        " 'no_repeat_ngram_size': 3,\n",
        " 'encoder_no_repeat_ngram_size': 0,\n",
        " 'num_return_sequences': 1,\n",
        " 'decoder_start_token_id': 2,\n",
        " 'use_cache': True,\n",
        " 'num_beam_groups': 1,\n",
        " 'diversity_penalty': 0.0,\n",
        " 'output_attentions': False,\n",
        " 'output_hidden_states': False,\n",
        " 'output_scores': False,\n",
        " 'return_dict_in_generate': False,\n",
        " 'forced_bos_token_id': 0,\n",
        " 'forced_eos_token_id': 2,\n",
        " 'remove_invalid_values': False})\n",
        "\n",
        "blocks = (HF_Seq2SeqBlock(before_batch_tfm=hf_batch_tfm), noop)\n",
        "\n",
        "dblock = DataBlock(blocks=blocks, get_x=ColReader('content'), get_y=ColReader('title'), splitter=RandomSplitter())"
      ],
      "metadata": {
        "id": "PVF956tmrr_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dls = dblock.dataloaders(articles, bs=2) #change bs to higher value after adjusting the head value based on resources"
      ],
      "metadata": {
        "id": "160LC_Ogrux-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28f3e57f-9408-4c1b-81f1-81ce4cc19c77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dls.train.items), len(dls.valid.items)"
      ],
      "metadata": {
        "id": "U-aV0a20vHZv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91eb5d5d-9ab6-4a80-b202-d7abac248703"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = dls.one_batch()\n",
        "len(b), b[0]['input_ids'].shape, b[1].shape"
      ],
      "metadata": {
        "id": "vpIQExZuvLcp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d3ec304-d078-4618-ecb2-5b380761aa01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, torch.Size([2, 1024]), torch.Size([2, 137]))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dls.show_batch(dataloaders=dls, max_n=2) #max_n to show the loaded batch"
      ],
      "metadata": {
        "id": "DI0rT11kvTIK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a41d5adb-cbdc-4e3d-ffcc-8ec5628d1857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1. Chief Ministers Relief Fund Application- Requirement analysis, Designing and Development and security auditing and Maintenance of Chief Ministers Relief Fund web based Bilingual Application for Chief Ministers Office, Government of Maharashtra using Open source technology in MVC model (Platform: Java, Struts2,PostgreSQL)- For this entire SDLC is followed and with special emphasis on users requirement specifications. Developed modules consisting of Citizen Centric Services like online donation and online application submission, Payment verification, Receipt generation, Enquiry services using Payment Gateway, with SMS, Email integration. Developed complete work flow based Back Office application resulting in automation of complete process followed in CMRF office. 2. RTI Online for Government of Maharashtra- Successful roll-out of the Maharashtra instance of RTI Online application in all the districts of Maharashtra. Coordination in resolving all the issues in the application. Training the department and district officials. Meeting with the departments for resolving issues, taking requirements, suggestions and change requests regarding development on the applications on daily basis. 3. RTI Portal for Government of Maharashtra - Requirement analysis, Designing and Development and security auditing of RTI Portal for Government of Maharashtra using Open source technology in MVC model (Platform:Java, Struts2,PostgreSQL)- For this entire SDLC is followed and with special emphasis on users requirement specifications. Developed modules consisting of Citizen Centric Services like search PIO, proactive disclosures. 4. Maharashtra Grievance from Central PG Portal: Implementation of PG Portal for all department of Secretariat, including attached offices. In order to dispose-off these large volumes of grievance, involved in technical discussions held with senior officials of Government of Maharashtra and defined Standard Operating Procedure(SOP) to forward and process these grievances. Training the department officials on creating further level accounts to forward and process these grievances. 5. SIC Online Application for State Information Commission, Maharashtra- Involved in Requirement analysis, Designing, Testing and Implementation of SIC Online Application. 6. Technical support and hand holding the all user departments for successful implementation of ICT projects. 7. Training and capacity building being core to project implementation, regular training and various capacity building programs were conducted successfully. 8. Regularly attended meetings on projects to suggest creative, innovation and indigenous ICT solutions to the users. 9. Involved in technical documentation like preparation of SRS and User Manuals. Design and Development:1. Chief Ministers Relief Fund - Development, Enhancement and Maintenance of Chief Ministers Relief Fund monitoring application as per the requirements of Chief Ministers Office using Open Source technology, automating entire procedure to receive onlinedonation and application, scrutinize, approve and provide relief to citizen (Platform: Java, Struts 2, PostgreSQL). Enhancement of existing modules like-Donation Receipt Printing, Application Scrutiny, Search module, Reports, Letters, Master Updation, Addition of Farmer's Relief Fund for Online Donation- Server Monitoring and maintenance- Initiation of Security audit for CMRF Office module. 2. RTI Portal - Design, Development, Security Audit, Hosting and Launch of bilingual RTI Portal as per the requirements of General Administration Department, Maharashtra. (Platform: Java, Struts 2, PostgreSQL). Server Monitoring and maintenance3. Credit and Sales monitoring application - Design, Development,Security Audit of Credit and Sales monitoring application for Canteen, Government of Maharashtra (Platform: Java, Struts 2, MySQL). Implementation and Roll-out:4. RTI Online - Implementation of RTI Online Application for all Tehsils of Maharashtra. Code changes in Static Pages as per request. Training and support to all Public authorities under RTI Online. Preparing proposal for Implementation of RTI Online for 320 Tehsil offices of Maharashtra. Server Monitoring and maintenance5. Public Grievance Portal - Implementation, Training of Public Grievance Portal for departments in Secretariat of Maharashtra and other attached offices for full roll-out. 6. SIC Online application - Requirement study, Analysis, Designing, coordination in development and Inauguration of SIC Online application as per the requirements of State Information Commission, Maharashtra. 7. MahaPAR - Coordination in Implementation, Training and Support of MahaPAR(Performance Appraisal System) for Government of Maharashtra. Development, Enhancement and Maintainence:1. Chief Ministers Relief Fund - Development, Enhancement and Maintenance of Chief Ministers Relief Fund monitoring application as per the requirements of Chief Ministers Office using Open Source technology, automating entire procedure to receive online donation and application, scrutinize, approve and provide relief to citizen (Platform: Java, Struts 2, PostgreSQL). 2. SIMNIC - Enhancement, Security audit, Vulnerability assessment, Hosting of application on Cloud. (Platform: Java, MySQL). 3. Credit and Sales monitoring application - Design, Development of Credit and Sales monitoring application for Canteen, Government of Maharashtra (Platform: Java, Struts 2, MySQL). 4. RTI Portal - Design, Development and launch of</td>\n",
              "      <td>The officer was involved in - Requirement analysis, Designing and Development and security auditing and Maintenance of web based Chief Ministers Relief Fund project - Bilingual Application for Chief Ministers Office, using Open source technology in MVC model (Platform:Java, Struts2, PostgreSQL) - Citizen Centric Services like online donation and online application submission, Payment verification, Receipt generation, Enquiry services using Payment Gateway with SMS, Email integration. - Implementation of RTI online and RTI Portal - Coordination in Implementation, Training and Support of MahaPAR(Performance Appraisal System) - Sampark, SIMNIC Mobile Application - Credit and Sales monitoring application</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Enhance and Redesigned the Budget preparation and printing module due Non-plan and Plan merger. Visualized real time position of budget with UDAY or without UDAY and Reduced Processing time. Set a procedure of Office and designation creation process for PD accountIntroduce the PD account Office ID and designation code. Made online and reduce time consuming for PD fund transfer sanction and PD opening sanction to reduced Paper work. Standardised the PD fund transfer sanction report and sanctionsImproved processes due to re-engineering of various legacy and existing processes that includes re-designing of formats, elimination of traditional method etc. Real time availability of Information and reports has speeded the compliance to stakeholder. Master codes are standarized of PD fund transfer sanction reference number. Real time postion of state in budget study and at a glance with UDAY or without UDAY conceptEffect of UDAY in varous Budget volumes with UDAY or without UDAY conceptSubordinate users creation module for WAM(Works accounting monitoring system) usersDummy Budget Prepared. Dummy Budget Prepared in very short time earlier it was very time consuming processAutomatic check built in system for Budget Estimation at HoD, AD, BFC level due to Non plan and plan merger. Budget Printing in A4 size earlier it was in A3 Size. Budget is available to all controlling officers automatically. Budget Preparation time is reduce earlier it was very time consuming processProrata charges and percentage charges process is automatic. Automatic Supplementary budget is generated. Excess-saving statement generated and process for re-app is automatic. Automatic re-enforcement process. Budget Estimation formats reduce from 33 to 13 and budget estimation time is reduce. Automatic Compilation of Budget Estimation. Real time Budget and Expenditure monitoring is possible. Budget control is effective. Online budget proposal and reports are prepared automatically through system. Automatically information actual,Budget estimates,Revised estimates,sanction post,telephone,computer and vehicle are available in performas. Budget available in different parameters like Hod,Admin,BFC unit, Major head,demand, head type etc Modification in PFMS integration with SFTP server due to Non-Plan and Plan merger concept. Designed and developed new algorithmsfunctions for various process due to Non-Plan and Plan merger concept. Measuring Performance monitor of application and databaseDatabase backup plans and re- indexing plans using SSISOptimization, Testing and Reviewing of code developed by team members. Maintenance and Troubleshooting at application level and database level Enhance and Redesigned the Budget preparation and printing module due Non-plan and Plan merger. Visualized real time position of budget with UDAY or without UDAY and Reduced Processing time. Set a procedure of Office and designation creation process for PD accountIntroduce the PD account Office ID and designation code. Made online and reduce time consuming for PD fund transfer sanction and PD opening sanction to reduced Paper work. Standardised the PD fund transfer sanction report and sanctionsImproved processes due to re-engineering of various legacy and existing processes that includes re-designing of formats, elimination oftraditional method etc. Real time availability of Information and reports has speeded the compliance to stakeholder. Master codes are standarized of PD fund transfer sanction reference number. Real time postion of state in budget study and at a glance with UDAY or without UDAY conceptEffect of UDAY in varous Budget volumes with UDAY or without UDAY conceptSubordinate users creation module for WAM(Works accounting monitoring system) usersDummy Budget Prepared. Dummy Budget Prepared in very short time earlier it was very time consuming processAutomatic check built in system for Budget Estimation at HoD, AD, BFC level due to Non plan and plan merger. Budget Printing in A4 size earlier it was in A3 Size. Budget is available to all controlling officers automatically. Budget Preparation time is reduce earlier it was very time consuming processProrata charges and percentage charges process is automatic. Automatic Supplementary budget is generated. Excess-saving statement generated and process for re-app is automatic. Automatic re-enforcement process. Budget Estimation formats reduce from 33 to 13 and budget estimation time is reduce. Automatic Compilation of Budget Estimation. Real time Budget and Expenditure monitoring is possible. Budget control is effective. Online budget proposal and reports are prepared automatically through system. Automatically information actual,Budget estimates,Revised estimates,sanction post,telephone,computer aand vehicle are available in performas. Budget available in different parameters like Hod,Admin,BFC unit, Major head,demand, head type etcSecure login access with OTP. IFMS SSO portal Single Sign on for all application of IFMS. Introduced new gender budget process (Scheme wise) Workshop organised for IMF on macro-eco analysis,forecasting and GPSModification in PFMS integration with SFTP server due to Non-Plan and Plan merger concept. Designed and developed new algorithmsfunctions for various process for gender budget concept. Measuring</td>\n",
              "      <td>The officer was involved in - NIC Data quality Challenges 2020 and shortlisted in 2nd round - Performance fine tuning, testing and reviewing of code of land records database and Shalldarpan database. - Digital Signature in PD opening module, PD fund transfer, Re- appropriation module and BFC MoM - Organising the IMF on macro- eco analysis, forecasting and GPS Modified budget due to Non- Plan and Plan merger concept - Designed and developed new algorithms/functions for various process for gender budget concept.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "6yxihN6yrwpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq2seq_metrics = {\n",
        "        'rouge': {\n",
        "            'compute_kwargs': { 'rouge_types': [\"rouge1\", \"rouge2\", \"rougeL\"], 'use_stemmer': True },\n",
        "            'returns': [\"rouge1\", \"rouge2\", \"rougeL\"]\n",
        "        },\n",
        "        'bertscore': {\n",
        "            'compute_kwargs': { 'lang': 'en' },\n",
        "            'returns': [\"precision\", \"recall\", \"f1\"]\n",
        "        }\n",
        "    }"
      ],
      "metadata": {
        "id": "jbyCMTIprye1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = HF_BaseModelWrapper(hf_model)\n",
        "learn_cbs = [HF_BaseModelCallback]\n",
        "fit_cbs = [HF_Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)]\n",
        "\n",
        "learn = Learner(dls, \n",
        "                model,\n",
        "                opt_func=ranger,\n",
        "                loss_func=CrossEntropyLossFlat(),\n",
        "                cbs=learn_cbs,\n",
        "                splitter=partial(seq2seq_splitter, arch=hf_arch)).to_fp16()\n",
        "\n",
        "learn.create_opt() \n",
        "learn.freeze()"
      ],
      "metadata": {
        "id": "ql-0_8Hbr03D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "6af9eada39694bd48fc00af2f4f3f736",
            "a7645cf623934223afe1848a95d5bb91",
            "c7610ef038d0484e908aa35890001180",
            "86bf90726a504ea297c63bda1617ead6",
            "e6b2474ddc5a4ca6ae28a95ec1308e63",
            "236c36875393430b8bc5abdeeb4391a3",
            "dced7766d52c4a99bced3c9bcdf12854",
            "b32074b8763347059fb0a15f413640e4",
            "86c449013db3408e9601966c59bdfe0d",
            "2eec6499d95a40f6888319a2b857d034",
            "011608cad43f465b8abb84b60b3e5f9e",
            "45a924b098b84e6d88cbca08aaa75883",
            "fd6db232d07f47aaa335fa4b9bdaa969",
            "c955d2812fa94de6873f8eac663cfc8b",
            "55725f79e5004dc9bd7a104dcb9a6548",
            "f5cf7a987aa34c2f8e90bd7766f7217e",
            "510d66d080104750a8f0acf0b6c534ec",
            "ef64a4aff3314bfd81980def50153389",
            "a777605da56f46f3a1c3d19acd156689",
            "cfd823c1a3684ca9a898ebe3d37eaaed",
            "8cf35e4736364e8dba5dedefde44cb4e",
            "050fab9dd897410ca544909485ffd565"
          ]
        },
        "outputId": "2fa67a11-366f-420d-ca4f-d810feba57f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/blurr/modeling/seq2seq/core.py:42: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  compute_func = hf_load_metric(metric_name).compute\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6af9eada39694bd48fc00af2f4f3f736"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.92k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45a924b098b84e6d88cbca08aaa75883"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#learn.lr_find()"
      ],
      "metadata": {
        "id": "r1T8qBFovjcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#b = dls.one_batch()\n",
        "#preds = learn.model(b[0])\n",
        "#len(preds),preds[0], preds[1].shape"
      ],
      "metadata": {
        "id": "WPBvQRCkvl4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#b = dls.one_batch()\n",
        "#preds = learn.model(b[0])\n",
        "#len(preds),preds[0], preds[1].shape"
      ],
      "metadata": {
        "id": "VBsHzptsvmt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.fit_one_cycle(300, lr_max=3e-5, cbs=fit_cbs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d176649caf25402ca1f79bd94ecd0325",
            "e16b579bc168497081307cb2344bf4a8",
            "38b1d971281b4ffd96a1ce1075d54e27",
            "7fe33bd32d22401ab61d3c927e96ee16",
            "bd9922b70bed4308ab9cc6cad3293ce0",
            "75424f7915db46539867cd45c9e17a64",
            "cc70b1c13c2b49faab45771b17624928",
            "04f0d20443c14a2a81d0022ffa1744c3",
            "67ba25be82d440499712326815b1abd7",
            "fc619dc1dfb84eea8f88fac42d477b5c",
            "404c35544f364bbea352a61a616ba3e0",
            "bf058328bd4c421f8e938ff0b5963304",
            "32e6a9a4b709436dbe6ece900be10a03",
            "913dc7366e21479db37d95f790fa4df4",
            "d2f759cbad954607ae95236b2ad303af",
            "6b58e41f8fac4cd1864d21f3f9cda42a",
            "e417b612c24d48b5bd8254c210178d0f",
            "5cb78f3c2a6441a28fbbef231bd4aaaf",
            "03b06ddbf235474fb46597275dd82188",
            "c54972622de941af8fbf85d4fc57ac8a",
            "8b3e23403e2a4dd79626474f805e649a",
            "b77dc1a175ed412684ce2ed6379a6e1a",
            "290f14b74a324c3eb14eede455050366",
            "7bdd20a3637a45f3a699d46f26cda390",
            "d177f02485a34545a3d7fa788893d970",
            "d0a7ebd4f06c4d8887847750817792af",
            "4b7a27f3ea84413b9425c5d249263fce",
            "e7b329ea7cff43699c5b0f18f2f04b93",
            "168c1187a3b04368b70f50a6156888fd",
            "d5c1af9767a740bd8a8310ee7c632552",
            "913d388d1b684372a1603ccdf660170c",
            "7ed707f637e54ed098f8365e8773b8e7",
            "edc07276177d464495d8c7052c73bee8",
            "2460d5314f0d440d9338396ea345568c",
            "08512ce8a719466ca82a89dddab40a6e",
            "0c184a616d474355a71e2a44650a2ef1",
            "017f184efe8e4222889999333db90448",
            "826fd887504b416ca3d70a53a2889ff0",
            "6be8f4a68a7c414cb2b98fb1acaa548b",
            "d9facb776c7544c5859026c6b6e99ce6",
            "21f86f8cad994dc6ac3691f4e1c556fe",
            "64b8a4576b66452bb6bc4d675f4cfd7f",
            "a06e4f1788cf4417a194a56e6076d73d",
            "dde44eb2553b46e88160d2f5ef8d2132"
          ]
        },
        "id": "EQdznqhVr2mp",
        "outputId": "df30abf0-9766-46bd-fb4f-69138cbd0b7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>rouge1</th>\n",
              "      <th>rouge2</th>\n",
              "      <th>rougeL</th>\n",
              "      <th>bertscore_precision</th>\n",
              "      <th>bertscore_recall</th>\n",
              "      <th>bertscore_f1</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>5.399680</td>\n",
              "      <td>4.010181</td>\n",
              "      <td>0.403950</td>\n",
              "      <td>0.184280</td>\n",
              "      <td>0.268859</td>\n",
              "      <td>0.856529</td>\n",
              "      <td>0.856744</td>\n",
              "      <td>0.856596</td>\n",
              "      <td>00:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>5.397067</td>\n",
              "      <td>3.961231</td>\n",
              "      <td>0.415355</td>\n",
              "      <td>0.198661</td>\n",
              "      <td>0.269081</td>\n",
              "      <td>0.858897</td>\n",
              "      <td>0.861278</td>\n",
              "      <td>0.860066</td>\n",
              "      <td>00:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>5.330453</td>\n",
              "      <td>3.800684</td>\n",
              "      <td>0.410632</td>\n",
              "      <td>0.183847</td>\n",
              "      <td>0.266889</td>\n",
              "      <td>0.857488</td>\n",
              "      <td>0.858431</td>\n",
              "      <td>0.857920</td>\n",
              "      <td>00:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>5.190289</td>\n",
              "      <td>3.412344</td>\n",
              "      <td>0.402401</td>\n",
              "      <td>0.204908</td>\n",
              "      <td>0.290914</td>\n",
              "      <td>0.857618</td>\n",
              "      <td>0.866415</td>\n",
              "      <td>0.861827</td>\n",
              "      <td>00:19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>5.006110</td>\n",
              "      <td>3.214670</td>\n",
              "      <td>0.394968</td>\n",
              "      <td>0.177903</td>\n",
              "      <td>0.282113</td>\n",
              "      <td>0.858673</td>\n",
              "      <td>0.856874</td>\n",
              "      <td>0.857756</td>\n",
              "      <td>00:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>4.797182</td>\n",
              "      <td>2.847327</td>\n",
              "      <td>0.433994</td>\n",
              "      <td>0.202865</td>\n",
              "      <td>0.295397</td>\n",
              "      <td>0.860914</td>\n",
              "      <td>0.865757</td>\n",
              "      <td>0.863279</td>\n",
              "      <td>00:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>4.547370</td>\n",
              "      <td>2.602866</td>\n",
              "      <td>0.393013</td>\n",
              "      <td>0.201873</td>\n",
              "      <td>0.282069</td>\n",
              "      <td>0.853772</td>\n",
              "      <td>0.862166</td>\n",
              "      <td>0.857738</td>\n",
              "      <td>00:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>4.271977</td>\n",
              "      <td>2.109189</td>\n",
              "      <td>0.418954</td>\n",
              "      <td>0.211662</td>\n",
              "      <td>0.294878</td>\n",
              "      <td>0.853256</td>\n",
              "      <td>0.867104</td>\n",
              "      <td>0.859993</td>\n",
              "      <td>00:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>3.961857</td>\n",
              "      <td>1.894923</td>\n",
              "      <td>0.409740</td>\n",
              "      <td>0.210643</td>\n",
              "      <td>0.292098</td>\n",
              "      <td>0.861792</td>\n",
              "      <td>0.865301</td>\n",
              "      <td>0.863417</td>\n",
              "      <td>00:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>3.653217</td>\n",
              "      <td>1.656645</td>\n",
              "      <td>0.466570</td>\n",
              "      <td>0.242815</td>\n",
              "      <td>0.337163</td>\n",
              "      <td>0.864874</td>\n",
              "      <td>0.871950</td>\n",
              "      <td>0.868271</td>\n",
              "      <td>00:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>3.352900</td>\n",
              "      <td>1.572919</td>\n",
              "      <td>0.460752</td>\n",
              "      <td>0.237914</td>\n",
              "      <td>0.339669</td>\n",
              "      <td>0.865754</td>\n",
              "      <td>0.870930</td>\n",
              "      <td>0.868175</td>\n",
              "      <td>00:16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>3.071852</td>\n",
              "      <td>1.503912</td>\n",
              "      <td>0.462559</td>\n",
              "      <td>0.267196</td>\n",
              "      <td>0.334525</td>\n",
              "      <td>0.867091</td>\n",
              "      <td>0.876980</td>\n",
              "      <td>0.871971</td>\n",
              "      <td>00:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>2.810476</td>\n",
              "      <td>1.452111</td>\n",
              "      <td>0.471539</td>\n",
              "      <td>0.269650</td>\n",
              "      <td>0.332116</td>\n",
              "      <td>0.869770</td>\n",
              "      <td>0.878536</td>\n",
              "      <td>0.874094</td>\n",
              "      <td>00:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>2.570983</td>\n",
              "      <td>1.412208</td>\n",
              "      <td>0.518252</td>\n",
              "      <td>0.327106</td>\n",
              "      <td>0.377185</td>\n",
              "      <td>0.871615</td>\n",
              "      <td>0.890173</td>\n",
              "      <td>0.880648</td>\n",
              "      <td>00:20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>2.347849</td>\n",
              "      <td>1.412724</td>\n",
              "      <td>0.529612</td>\n",
              "      <td>0.349758</td>\n",
              "      <td>0.402265</td>\n",
              "      <td>0.883294</td>\n",
              "      <td>0.893044</td>\n",
              "      <td>0.888086</td>\n",
              "      <td>00:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>2.147004</td>\n",
              "      <td>1.408549</td>\n",
              "      <td>0.483253</td>\n",
              "      <td>0.281684</td>\n",
              "      <td>0.336353</td>\n",
              "      <td>0.872806</td>\n",
              "      <td>0.880826</td>\n",
              "      <td>0.876488</td>\n",
              "      <td>00:16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.963164</td>\n",
              "      <td>1.409206</td>\n",
              "      <td>0.507596</td>\n",
              "      <td>0.308833</td>\n",
              "      <td>0.376312</td>\n",
              "      <td>0.882923</td>\n",
              "      <td>0.883471</td>\n",
              "      <td>0.883094</td>\n",
              "      <td>00:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.799957</td>\n",
              "      <td>1.408659</td>\n",
              "      <td>0.497885</td>\n",
              "      <td>0.304259</td>\n",
              "      <td>0.368157</td>\n",
              "      <td>0.875006</td>\n",
              "      <td>0.885285</td>\n",
              "      <td>0.879878</td>\n",
              "      <td>00:16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.656371</td>\n",
              "      <td>1.416153</td>\n",
              "      <td>0.472463</td>\n",
              "      <td>0.275750</td>\n",
              "      <td>0.340507</td>\n",
              "      <td>0.872524</td>\n",
              "      <td>0.877343</td>\n",
              "      <td>0.874655</td>\n",
              "      <td>00:16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.532628</td>\n",
              "      <td>1.418255</td>\n",
              "      <td>0.478957</td>\n",
              "      <td>0.309533</td>\n",
              "      <td>0.362395</td>\n",
              "      <td>0.874564</td>\n",
              "      <td>0.885424</td>\n",
              "      <td>0.879530</td>\n",
              "      <td>00:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.422184</td>\n",
              "      <td>1.421465</td>\n",
              "      <td>0.487521</td>\n",
              "      <td>0.324382</td>\n",
              "      <td>0.368091</td>\n",
              "      <td>0.874118</td>\n",
              "      <td>0.887608</td>\n",
              "      <td>0.880369</td>\n",
              "      <td>00:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.329989</td>\n",
              "      <td>1.423658</td>\n",
              "      <td>0.487521</td>\n",
              "      <td>0.324382</td>\n",
              "      <td>0.368091</td>\n",
              "      <td>0.874118</td>\n",
              "      <td>0.887608</td>\n",
              "      <td>0.880369</td>\n",
              "      <td>00:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.249892</td>\n",
              "      <td>1.422654</td>\n",
              "      <td>0.487521</td>\n",
              "      <td>0.324382</td>\n",
              "      <td>0.368091</td>\n",
              "      <td>0.874118</td>\n",
              "      <td>0.887608</td>\n",
              "      <td>0.880369</td>\n",
              "      <td>00:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.181735</td>\n",
              "      <td>1.422370</td>\n",
              "      <td>0.487521</td>\n",
              "      <td>0.324382</td>\n",
              "      <td>0.368091</td>\n",
              "      <td>0.874118</td>\n",
              "      <td>0.887608</td>\n",
              "      <td>0.880369</td>\n",
              "      <td>00:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.127980</td>\n",
              "      <td>1.422182</td>\n",
              "      <td>0.487521</td>\n",
              "      <td>0.324382</td>\n",
              "      <td>0.368091</td>\n",
              "      <td>0.874118</td>\n",
              "      <td>0.887608</td>\n",
              "      <td>0.880369</td>\n",
              "      <td>00:17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d176649caf25402ca1f79bd94ecd0325"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf058328bd4c421f8e938ff0b5963304"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "290f14b74a324c3eb14eede455050366"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2460d5314f0d440d9338396ea345568c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn.show_results(learner=learn, max_n=3)"
      ],
      "metadata": {
        "id": "LSSI54eav8Jf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6da27cb8-108e-4466-811d-1de68aea98cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3707: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>To analyse a technical matter and to provide its systematic, IT based situation-effective solution to the user department in the district. To model and manage the databases of Polling Personnels,EVM,Booths, and prepare various randomization reports in the LITTIPARA assembly bye-election 2017. To render the technical coordination for an effective IT based solution in various e-governance projects of state and central level. To work as a technical IT support adviser to DC of the district. To impart training on various e-governance project to the respective user departments. To solve the technical IT issues arising out of the implementation of various e-governance projects of user Department. To enhance the competence of technical manpower in the district in order for them to be competent enough to manage smooth functioning of various project. To work as a technical member in District e-Governance Society. In a nutshell, to act in a role of a technical bridge in the district for every IT based Issueproblem in order to provide a situation-effective, cost-effective and innovative solution in the implementation of all e-Governance projects in the district. To develop and migrate the District website on S3WaaS. I was the 2nd in Jharkhand to Migrate my District's Website on S3Waas. Comprehensive Technical Co-ordination at District level in various Important Central Level Digital India Initiatives taken by our honorable PM. To analyse a technical matter and to provide its systematic, IT based situation-effective solution to the user department in the district. To manage the databases of Polling Personnels,EVM,Booths, and prepare various randomization reports in the Municipal Election 2018 in the district. To manage the databases of Polling Personnels,Booths and prepare various randomization reports in the Panchayat By-Election 2018 in the district. To render the technical coordination for an effective IT based solution in various e-governance projects of state and central level. To work as a technical IT support adviser to DC of the district. To impart Training to the Concerned departments on the Website data upload in the Most important Aspiration District Programme of NITI AayogTo impart training on various e-governance project to the respective user departments. To solve the technical IT issues arising out of the implementation of various e-governance projects of user Department. To enhance the competence of technical manpower in the district in order for them to be competent enough to manage smooth functioning ofvarious project. To work as a technical member in District e-Governance Society. In a nutshell, to act in a role of a technical bridge in the district for every IT based Issueproblem in order to provide a situation-effective, cost-effective and innovative solution in the implementation of all e-Governance projects in the district. To provide ICT support to the district departments as per their requirements in an IT related Matter. To manage databases of Polling Personnel in the general election 2019. To Provide training to the concerned users in the district on the various ICT applications used in the General Election 2019. To execute an application which is yet to be launched in the district for its further functioning by the respective users. To provide technical support to the district in the Email Services. To provide implementation support to the district for Gem Portal. To work as a technical member in the District e-Governance Society. To overall help the users in upgrading their reach in the realm of Digital India. i) Requirement Analysis: Did requirement analysis in the development of a website for navigating wells and ponds in the district under Jal Jeewan Hariyali scheme of the state government. ii) Requirement Specification: Specified the design and development requirements to the development agency in the development of the application. iii) Software Application Testing : Tested the following applications developed by NIC in order for its further improvements by the development team a) Elecon b) Aapda c) MedhaSoft etc. iv) Training: Provided training to the respective user departments on the following applications : a) MedhaSoft b) ICJS portal c) NIC e-Forms website d) Jeewan praman appication v) Software Implementation : Implemented the following softwares in the district : a) MedhaSoft b) ICJS c) CyberPolice d) Elecon for PACS election 2019vi) ICT and e-Governance Support: provided ICT and e-Governance support to the district on various e-Governance schemes of the government like Jal jeewan hariyali, Jal shakti abhiyan,NDAL-ALIS Portal etc. vii) Database management: managed the various databases of Polling Personnel,PCCP,Counting Personnel etc. related to PACS election 2019. viii) Report Geneartion : technically generated various randomization reports related to polling personnel, PCCP and Counting personnel in the PACS election 2019. ix) Capacity building : provided</td>\n",
              "      <td>The officer was involved in - Model and manage the databases of Polling Personnels, EVM, Booths, and prepare various randomization report for assembly and municipal elections - Functioning as technical bridge in the district for every IT based Issue/problem in order to provide a situation- effective, cost- effective and innovative solution in the implementation of all e- Governance projects in the district. - Did requirement analysis in the development of a website for navigating wells and ponds in the district under Jal Jeewan Hariyali scheme</td>\n",
              "      <td>The officer was involved in - Model and manage the databases of Polling Personnels,EVM,Booths, and prepare various randomization reports in the LITTIPARA assembly bye-election 2017 - Worked as technical bridge in the district for every IT based Issueproblem in order to provide a situation- effective, cost- effective and innovative solution in the implementation of all e-Governance projects in theDistrict. - Did requirement analysis in the development of a website for navigating wells and ponds in the District under Jal Jeewan Hariyali scheme of the state government. - Implemented the following softwares in the. district : a MedhaSoft camanhaSoft) Software for EleconS for election 2019vi) ICT and e- Governance support provided to the government like Jal jeewan hariali, shaktiyan abhiyan,NDALIS Portal vii) Report Geneartion generated for randomization related to polling personnel in the PACS election 2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NIC DNH UT Centre is playing vital role in e-governance activity as well as Digital India' programme. Here in DNH UT, The NIC UT centre offers so many services to the various departments belong to DNH UT Administration and many centre govt offices. We offer wide range of e-solution like (Gepnic-eProcurement, Vahan, Sarathi, Land Records NLRMP, eTPDS. NIC Cloud - Meghraj Support, Web site hosting support, Video Conferencing services and many more. I have been involved in implementation and deployment of few projects like A) Gepnic- eProcurement. Imparted training on GEPNIC and DSC handling. B) I used to take care of email creation and user profile using Delegated Administration Console. C) I used to take care of Video Conferencing services from NIC VC studio as well as Desktop VC Solution. We provide technical assistance to user during VC session if they require. D) I have been involved in smooth functioning of NIC-NET and its Connectivity. E) I imparted some lecture on technical session on Data Base Design C. Net and SQL to some programmer working in NIC Under various projects. Software Application design, Development and Implementation, Requirements Gathering and Analysis as per SW Engineering Principles, Utilizing Standard Methodologies. Technical Support and Coordination Training and Capacity Building, SW Development,Deployment, Configuration,Cyber security Learning about the security threats and how to deal with and applying the same in application development and security auditing. Computer Networking, NKN monitoring and Coordination with other agencies like P. G. C. L., B. S. N. L.,S. W. A. N. (UTWAN), Providing Email and VC services to the Administration, playing Role of Advisory to UT District administration in ICT project and various e-gov Initiative. A)DBT Application development and deployment on cloud. integration of NPCIL,Aadhar Authentication services through NIC. B)Gepnic- e-Procurement. Imparted training on GEPNIC and DSC handling. C)Coordination and monitoring of NKN Network of NIC. D)Video Conferencing services from NIC VC studio as well as Desktop VC Solution. E)Implementation of AEBAS System in Various govt. Department and PSU. F)Implementation and technical support for Smart Performance Appraisal Report Recording Online Window (SPARROW)G)Implementation and technical support for National Scholarship Portal, Public Finantial Management System for DBT. H)Implementation and technical support for GEM Portal. Software Application Requirements Gathering, design, Development and Implementation and Analysis as per SW Engineering Principles, Utilizing Standard Methodologies. Technical Support and Coordination Training and Capacity Building, SW Development, Deployment, Configuration, Cyber security Learning about the security threats and how to deal with and applying the same in application development and security auditing. Computer Networking, NKN monitoring and Coordination with other agencies like P. G. C. L., B. S. N. L. Providing Email and VC services to the Administration, playing Role of Technical Advisory to UT District administration in ICT project and various egov Initiative. A) Contributed in the development of SW which deals in randomization of pooling party. We developed this sw for Lokshabha Election 2019 as per the special requirement of DNH UT Administration. B) Contributed in the development of Macro Base Counting Sheets used during counting day of Lokshabha Election 2019 as per the special requirement of DNH UT Administration. C) Imparted and coordinated various training workshop related to various applications involved in process of Lokshabha Election 2019, such as i)cVIGIL - An online app for citizens to report on the model code of conduct violations during the election period. ii)Voter Helpline APP This app will allow users to easily find the information they are looking for. Citizens can browse the app based on their own interests and learn more about Election Process in a more engaging wayiii)PwD App - This is a pioneered application which provides the facility of informing the voter themselves as a person with the disability so that the same can be reflected in the electoral roll. D) Gepnic- e-Procurement. Imparted training on GEPNIC and DSC handling. E) Coordination and monitoring of NKN Network of NIC. F) Video Conferencing services from NIC VC studio as well as Desktop VC Solution. G) Providing technical support for many e-gov Applications such as 1) AEBAS System in Various govt. Department and PSU. 2) Smart Performance Appraisal Report Recording Online Window (SPARROW)3) National Scholarship Portal4) Public Financial Management System for DBT 5) Implementation and technical support for GEM Portal</td>\n",
              "      <td>The officer was involved in the - Development and implementation of Randomization application, cVigil App, Voter Helpline App and PwD app for the election process - Implementation of GEPNIC and DSC handling. - Promotion of e-Mail and VC solutions in the UT - Providing technical support for the implementation of AEBAS, SPARROW, National Scholarship Portal and Public Financial Management System for DBT</td>\n",
              "      <td>The officer was involved in - Implementation and deployment of few projects like Gepnic- eProcurement, Vahan, Sarathi, Land Records NLRMP, eTPDS, NIC Cloud - Meghraj Support, Web site hosting support, Video Conferencing services and many more. - Implemented and coordinated various training workshop related to various applications involved in process of Lokshabha Election 2019, such as i)cVIGIL - An online app for citizens to report on the model code of conduct violations during the election period. - Voter Helpline APP - Allows users to easily find the information they are looking for based on their own interests and learn more about Election in a more engaging way.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Predictions"
      ],
      "metadata": {
        "id": "F7fAtpx5r4ob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['content'][17]"
      ],
      "metadata": {
        "id": "1Lo5AAZJr64o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "b4704f57-7eba-4ad9-fb97-ceed7bd5fcba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1. Development of statistical report for e-registration that shows complete picture of the stateselected district within a selected period to track performance of deed registration. 2. Integration of ERegistration with RAS, Umang and CSC. 3. Integration of Various services of RCCMS like Judgement, Case Status etc with Umang App. 4. Creation of Scheduled Mail Service that sends emails to various administrative officers in districts regarding performance of each tehsilsubtehsil. 5. Relocation of scanned registered deeds data to the new provisioned storage. 6. Development of services of Scanned Deeds and Scanned mutation copy through CSC. 7. Integration of ERegistration status with HEPC dashboard. 8. Development of module of seeding details of disputed land in the RCCMS. 9. Development of portal for providing combined search page for properties in rural, ULB and HUDA under EoDB. 10. Development of stamp duty and registration fee calculation module and putting it onto the jamabandi website. 11. Under SARAL project, development of Services - Scanned Registered Deeds, Causelist and Judgement. 14. Development of GovLand Portal to facilitate the departments and government know the status of their properties. 15. Identifying security gaps in WebHalris, LRMailService and its Security Audit. 16. Updation of LGD as per the Revenue records of Haryana State. 17. Providing training to patwaris (Revenue Clerk) on e-registration. 1. Web Halris: WebHalris is a web based system that provides seamless integration of Haris and Halris system. Responsible for managing Databases, support, troubleshooting, development of modules Khasra Girdawari and Fard Badar. 2. LGD - Updation of LGD and mapping it according to the state specific revenue directory. 3. SARAL Haryana: Service Online based platform for Haryana state. Responsible for building services of revenue department as notified by government. Responsible for creation of services on the platform, creation of API, database management, updating, preparing user manuals, troubleshooting. Developed two new services namely appointment for deed registration and mutation request on SARAL platform. 4. ERegistration: Web based integrated solution for streamlining the requests for deed registration in Revenue Department. System is integrated with existing Haris system which is in client server mode, along with online WebHalris system and used to register deeds. Responsible for keeping it up and running, maintaining, troubleshooting including support and change management. 5. RCCMS- Revenue Court Cases Monitoring System is a web based solution to manage the court cases filed in the revenue courts. The system provides facilities like case filing, allotment, daily orders, judgements, causelist etc. 6. EoDB: Customizing existing systems for adhering to the Ease of Doing Business Guidelines. 7. Gov Land: Web application that lists government properties to various users. Allows them to update it and add and update government properties. 1. WebHalris: a. Migration of tehsilsubtehsil: 52 new tehsil migrated to webhalris. b. Developed report of filled girdawari performa. Made provision of importing JSON data to and from mobile app for eGirdawari. c. Supported in provisioning of new hardware in state data center for webhalris. Installation of application software, database, report servers for the same. d. Migrated existing webhalris site and databases to newly provisioned ICT. 2. SARAL: Optimized Appointment Service being providing through SARAL. Enforced checks. 3. ERegistration: Day to day support for e-registration system. Optimized eregistration module for bugs. Shifted villages within various tehsils as notified by the government. 4. RCCMS: providing support and troubleshooting for various courts as needed. Prepared custom reports for monitoring purpose by govnerment5. GovLand: provided technical support to Asset Management Cell for filling government lands on portal. Creation of new user role DRO having special rights. Preparation of various reports for monitoring progress by government6. PM Kisan: Created databases which contains eligible farmers for PM Kisan Samman Yojna. 7. MFMB: Created various APIs that provide base data on various parameters from land record databases. This data is used for farmer registration and buying hisher crop. 8. LGD: Created villages which were not there in LGD and required for creation under PMKisan Scheme. Also ensuring that all revenue villages exist in the LGD. 9. Jamabandi Portal: Provided guidance and support for development of new portal for jamabandi. Completed secuity audit. 10. EoDB: All points relating to land reforms have been completed under BRAP 2018 and BRAP 2019. 11. Bhu Naksha: Integration of Bhu Naksha with support from NIC HQ. A. Software Systems: 1. WEBHalris: Development, updating and maintenance of following modules: a. Integration with Online Appointment. b. Integration with HSVP . c. Integration with HSIIDC. d. Integration with Municipal Corporations through ULB. e. Integration with Housing Board Corporation. f. Updating stamp duty modules for single stamp duty, single deficiency check. g. Updating damage crop inspection module crop damage calculation. h. Development of Crop Damage Reports and related modules. i. Modules for Acquired Land under litigation and forest land. 2. Online Appointment: Development of new software solution for online appointment: a. Development of new modules to capture land details and integration with WebHalris. b. Development of modules to capture Mobile nos from EStamp and integration with SMSServices. c. Integration with DemoAuth for name authentication. d. Integration with EGRAS system of Treasury. e. Development of new module to capture plot details for HSVP and integration with HSVP. f. Development of new module to capture plot details for HSVP and integration with HSIIDC. g. Development of new module to capture plot details for HSVP and integration with ULBMunicipal Corporations. h. Development of modules for getting NOC from TCP and integration with Town and Country Planning. i. Integration with LMS for ligitations in civil courts for various properties. j. Integration with RCCMS for litigations in various revenue courts. k. Provisions for blocked khewat and khasra. 3. LRDataServices: Development of various WebMethods in LRDataServices in order to integrate online appointment system with Land record data and to integrate with MFMB. These methods provide interfaces to various applications of various department to get land ownership, cultivation, crop data. They also include methods to provide list of revenue estates according to various classifications used in Online appointment module. 4. ERegistration: Integration of Online Appointment module with ERegistration System. Shifting villages, new deed and subdeed types etc. Other activites include day to day support and maintenance. 5. RCCMS: Development of new module to seed mobile numbers of parties, and sending ESummon using SMS Service. Providing day to day and periodic reports to department. 6. SARAL: Monitoring and troubleshooting of various services including Appointment for Deed Registration, Mutation Request, Daily Causelist, Scanned copy of deed, Scanned copy of Judgement. Responsible for seamless communication between SARAL and APIs which provide data access and enable service delivery. Updated appointment module as per requirements of department to check estamp on booking time. 7. TCPApp: Providing day to day support to TCP Department. 8. DigitalSign Creation of web service to digitally sign documents as per requirement by Revenue department to provide digitally signed copies of scanned registered deeds, mutations and RoR. Also updated Jamabandi Website for providing digitally signed copies 9. Jamabandi Website Managing SSL on the website, Web Hosting, Digitally signing, support. B. Operations: 1. Migration: Migration of tehsilsubtehsil to webhalris. A total of 37 tehsilsubtehsil were migrated online to WebHalris. 2. Web Hosting: Hosting of various websites and services over IIS. It includes OnlineAppointment, SMSService, updating TokenService, LRDataService etc. 3. Server Management: Management of servers including DBServer, WebServer etc. . 4. Maintenance: Scheduling activities such as Backup and maintenance plans. C. Capacity Building: 1. Training to PatwariRevenue Officials: Provided training to patwarisrevenue officials on WebHalris, ERegistration, RCCMS. 2. Training to Call Centre Executives: Training to SARAL Call Centre executives on online appointment sysD. Support:1. Troubleshooting: Troubleshooting assigned software systems in case of issues. 2. User Department New Requirements: embracing new requirements and upgrading existing systems. It includes OnlineAppointment, WebHalris, Khasra Girdawari, Kharaba APR etc. 3. Reports: Supporting administration with Ad-hoc as well as periodic reports as and when required. 1. Requirements Elicitation and Analysis includes gathering analysing requirements. A. Functional Requirements are collected primarily from user department (Department of Revenue, Government of Haryana) regarding development of new softwareAPIWeb-Service or a new functionality for any purpose etc. B. Non Functional Requirements: NFR such as reliability, maintainability, performance, Reusability, Adaptability and Security are must to be adhered to in order to development and implement in an enterprise vide integrated solution. C. Domain Requirements: Functional requirements in assigned projects are heavily domain specific and requires understanding domain of revenue and land records along with organization hierarchy. There requirements must be analysed for technical, operational and resource feasibility. In projects assigned, some of requirements include:a. Developement of provision of Exchange deed both intra and inter tehsil and district. b. Development of provision to exchange property in licenced colonies. c. Development of provision of cultivable agriculture land based on land type and fixing its stamp duty as per notification. d. Integration with SWAMITVA schemee. Registration with DLT as directed by DoT, MCIT, creation of SMS templates, implementing them in projects. f. Provision for registration of HSAMB and Housing Board outside urban area. g. Provision for document registration for NRI and OCI without UIDAIh. Provisioning deed type checking with Transfer permission in case of urban departments. i. Pushing post registration data to various deparments. j. Provisioning sale by panchayat, government, boardcorporations. k. Mapping of MC with tehsils. l. Calculation of MC share based on deeds registered, providing mechanism for verification of deeds by SRO, generation of bill. m. Updating Khasra Girdawari format as per new directions of revenue department and updation of Service and report for that. n. Creation, SSL implementation and Hosting of API for Ayushman Bharat scheme. o. Mapping of revenue villages with LGD and panchayat. 2. Design: while designing solution for any requirement, high-level and low-level design are considered. It is decided how to develop it, where to host it, what will be its input and output, how will it communicate to other modules, error handling method, database design, and place of module in the overall system. All this is done keeping in mind the existing architecture of system. 3. Development: Based on design consideration, system is developed. Till now in assigned projects, methodology has been using ASP. NET Framework and twitter for front end if required. SQL server is being used as Database in current architecture. 4. Integration: For integration of projects, Soap based Web Services and Restful Web API have been used. WebHalris internally is working with WCF based architecture with faade exposing functions through interfaces. 5. Unit, Integration and System testing is done for each and every module developed. 6. Implementation post system testing, code is finally pushed on WebServer and is implemented in the solution. 7. Support: Providing support to user department as and when required, such as generation of adhoc and periodic reports, incorporating new changes etc. 8. WebHosting: Hosting applicationsite as per suitable environment. Currently IIS is set for WebHost. 9. Maintenance In software projects, maintenance comes in form of changes or bugs. As both generate requirement, entire SDLC is repeated. 10. Database Design- SQL Server is being used as database server. All projects assigned till now has been developed using database-first approach. Tables are necessarily Normalized upto 3NF and if possible BCNF and 4NF based on requirements. 11. Database Management- includes monitoring and managing database size, their log size, performance, maintenance plans etc. Maintenance plans for all database has been created, with WebHalris database backups being pushed in backup appliance. Index are created and rebuild periodically. 12. ApplicationWeb Security: All software applications have been developed adhering to OWASP Top 10 guidelines. 13. ICT Monitoring and Maintenance: It includes management of ICT. Managing 13 Windows servers, with ICT created as IIS as WebHost, SQL Server as DBMS, SSRS as reporting Service along with AD and SAN Storage. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = learn.blurr_generate(df['content'][17], early_stopping=False, num_return_sequences=3)\n",
        "\n",
        "for idx, o in enumerate(outputs):\n",
        "    print(f'=== Prediction {idx+1} ===\\n{o}\\n')"
      ],
      "metadata": {
        "id": "ZdBArkrcr9Dq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "235a5fa4-409d-42cf-cc44-16ff36004e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py:1288: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 142 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Prediction 1 ===\n",
            " The officer was involved in - Integration of E registration with RAS, Umang and CSC. - Scanned Registered Deeds, Causelist and Judgement - RCCMS- Revenue Court Cases Monitoring System - Updation of LGD and mapping it according to the state specific revenue directory - Jamabandi Portal - PM Kisan Samman Yojna - Providing technical support for LGD reforms under BRAP 2018 and BRAP 2019\n",
            "\n",
            "=== Prediction 2 ===\n",
            " The officer was involved in - Integration of E registration with RAS, Umang and CSC. - Scanned Registered Deeds, Causelist and Judgement - RCCMS- Revenue Court Cases Monitoring System - Updation of LGD and mapping it according to the state specific revenue directory - Jamabandi Portal - PM Kisan Samman Yojna - Providing technical support for LGD reforms under BRAP 2018 and BRAP 2019 with support for support for jamabandi website.\n",
            "\n",
            "=== Prediction 3 ===\n",
            " The officer was involved in - Integration of E registration with RAS, Umang and CSC. - Scanned Registered Deeds, Causelist and Judgement - RCCMS- Revenue Court Cases Monitoring System - Updation of LGD and mapping it according to the state specific revenue directory - Jamabandi Portal - PM Kisan Samman Yojna - Providing technical support for LGD reforms under BRAP 2019 and BRAP 2018AP audit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference"
      ],
      "metadata": {
        "id": "XcHMvswDApT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "CF8ytBzngzyg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64839ed7-1cb3-4eb9-a301-a4ad6f09586e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn.metrics = None\n",
        "learn.export(fname='/content/drive/MyDrive/Summary_models/ft_cnndm_export_25epoch_large.pkl')"
      ],
      "metadata": {
        "id": "WRhq6emb-w5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Training and capacity building is core to project implementation. Regular trainings and various capacity building programmes were conducted successfully. These are on General Awareness on e-Governance and specific to applications as well. Delivered lectures during various events at different Govt forums and conferences so that Users can feel ease while operating ICT solution belongs to them. OperationalUser manuals prepared for the local projects. Played Technical Advisor role to Secretariat Administrative Department, UP Secretariat in implementation of innovative ICT solutions. In UP Secretariat NIC's playing its role as the prime advisor to various departments in ICT related solutions from hardware procurements to software developments. Involved in user specific customized ICT solutions in the form of Application software to fulfill the user needs and requirements. For this entire SDLC is followed and with special emphasis on users requirement specifications. Implemented Application software's pertaining to Secretariat Administrative Dept. of UP Secretariat. Extended full technical support in procurement and establishment of ICT Infrastructure in various depts. sections of UP Secretariat.. Documentation is very important for smooth implementation of any project. Involvement in technical documentation like preparation of SRS, various user Manuals i. e. for administrator, application, and operators, Brochures, Project Leaflets, etc. ICT Project proposals are vital for administration to take apt decision towards its implementation. Therefore, involved in preparing ICT project proposals for Secretariat Administrative Department of UP Secretariat as a whole and subsequently related DPRs also which facilitate design and development of the applications. Participated in Committees Boards on ICT projects, related to Secretariat administration Department, UP Secretariat. Attended and organized many ICT workshops and conferences for the awareness of services delivery web applications. Organized campaigns to provide awareness among people so that they can avail maximum benefit of schemes using ICT. Coordinated and extended full technical support to various depts. ( 7 buildings) of UP Secretariat for maintaining UPNICNET and emails etc. Internet connectivity to UP Secretariat is provided round the clock. Coordinated and extended full technical support to vidhan sabha for maintaining UPNICNET and emails etc. Internet connectivity to vidhan sabha is provided round the clock. Many times, it becomes important to upgrade the existing ongoing applications at par with the incoming new technologies and tools. All these add new dimension to existing applications and ease the entire process with new features. In the scenario of ever changing technologies, one has to upgrade and also impart the upgraded knowledge to users also. Hence, time to time, programs on Skill development on e-Governance were also conducted to upgrade new skills and get mutual benefits. PDI process- As a consultant to UP Secretariat, prepared technical specifications for hardware procurement for several ICT projects of UP Govt., Pre Delivery Inspection of procured hardware at plant level is also done. Regularly attended ICT Skill up-gradation and management oriented programmes at NIC Head qtr NIC UP State CSI seminars OEM seminars and other reputed institutions. Involved in user specific customized ICT solutions in the form of Application software to fulfill the user needs and requirements. For this entire SDLC is followed and with special emphasis on users requirement specifications. Implemented Application software's pertaining to Secretariat Administrative Dept. of UP Secretariat. Extended full technical support in procurement and establishment of ICT Infrastructure in various depts. sections of UP Secretariat. Training and capacity building is core to project implementation. Regular trainings and various capacity building programmes were conducted successfully. These are on General Awareness on e-Governance and specific to applications as well. Delivered lectures during various events at different Govt forums and conferences so that Users can feel ease while operating ICT solution belongs to them. OperationalUser manuals prepared for the local projects. Played Technical Advisor role to Secretariat Administrative Department, UP Secretariat in implementation of innovative ICT solutions. In UP Secretariat NIC's playing its role as the prime advisor to various departments in ICT related solutions from hardware procurements to software developments. Documentation is very important for smooth implementation of any project. Involvement in technical documentation like preparation of SRS, various user Manuals i. e. for administrator, application, and operators, Brochures, Project Leaflets, etc. ICT Project proposals are vital for administration to take apt decision towards its implementation. Therefore, involved in preparing ICT project proposals for Secretariat Administrative Department of UP Secretariat as a whole and subsequently related DPRs also which facilitate design and development of the applications. Participated in Committees Boards on ICT projects, related to Secretariat administration Department, UP Secretariat. Attended and organized many ICT workshops and conferences for the awareness of services delivery web applications. Organized campaigns to provide awareness among people so that they can avail maximum benefit of schemes using ICT. Coordinated and extended full technical support to various depts. ( 7 buildings) of UP Secretariat for maintaining UPNICNET and emails etc. Internet connectivity to UP Secretariat is provided\""
      ],
      "metadata": {
        "id": "pXOJaOvpX1DL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install bert-extractive-summarizer"
      ],
      "metadata": {
        "id": "E1aBorS6ndHM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from summarizer import Summarizer\n",
        "#model = Summarizer()\n",
        "#result = model(text, min_length=20)\n",
        "#summary = \"\".join(result)"
      ],
      "metadata": {
        "id": "NiK77rtPnwVy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "VfndD9rJn-DH",
        "outputId": "20a926e3-ba15-4208-d0f3-3be5fe3c816b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Training and capacity building is core to project implementation. Delivered lectures during various events at different Govt forums and conferences so that Users can feel ease while operating ICT solution belongs to them. Played Technical Advisor role to Secretariat Administrative Department, UP Secretariat in implementation of innovative ICT solutions. Implemented Application software's pertaining to Secretariat Administrative Dept. ICT Project proposals are vital for administration to take apt decision towards its implementation. Therefore, involved in preparing ICT project proposals for Secretariat Administrative Department of UP Secretariat as a whole and subsequently related DPRs also which facilitate design and development of the applications. Organized campaigns to provide awareness among people so that they can avail maximum benefit of schemes using ICT. 7 buildings) of UP Secretariat for maintaining UPNICNET and emails etc. Internet connectivity to UP Secretariat is provided round the clock. sections of UP Secretariat. Documentation is very important for smooth implementation of any project.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from datasets import disable_caching\n",
        "#disable_caching()"
      ],
      "metadata": {
        "id": "VRshLlOpCUX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import locale\n",
        "#def getpreferredencoding(do_setlocale = True):\n",
        "    #return \"UTF-8\"\n",
        "#locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "3-16LK7OqgzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install adapter-Transformers"
      ],
      "metadata": {
        "id": "0tDLeZIpoiLP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inf_learn = load_learner(fname='/content/drive/MyDrive/Summary_models/ft_cnndm_export_25epoch_large.pkl') #Pickle file stores the inference i.e. the predictions/model in it. \n",
        "summaries = inf_learn.blurr_generate(text, early_stopping=False) #test string"
      ],
      "metadata": {
        "id": "BDKAw0TMAs1l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74e2d1ae-7b6a-482f-fd1a-13c93ea83588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py:1288: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 142 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(summaries[0])"
      ],
      "metadata": {
        "id": "VX4syIAFrXy6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3cb7db7-bee9-4473-8835-abd969bdee52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The officer was involved in preparing ICT project proposals for Secretariat Administrative Department of UP Secretariat as a whole and subsequently related DPRs also which facilitate design and development of the applications. Delivered lectures during various events at different Govt forums and conferences so that Users can feel ease while operating ICT solution belongs to them. Implemented Application software's pertaining to Secretariats pertaining to UPNICNET and emails etc.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " The officer was involved in - Usage of Digital Signature Certificates for user authentication and role based access of databases - Virtual Private Network to access IVFRT applications - Encrypted private data is safely and securely sent over the public network via crypto tokens - Use of remote desktop applications such as AnyDesk, WebEx and TeamViewer to install, troubleshoot and configure applications and digital signature certificates. - Providing timely database reports to competent authority for effective project monitoring\n"
      ],
      "metadata": {
        "id": "i0nDCvtfMqYJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " The officer was involved in - Usage of Digital Signature Certificates for user authentication and role based access of databases3. Usage of Virtual Private Network to access IVFRT applications. - Encrypted private data is safely and securely sent over the public network via crypto tokens. - Use of remote desktop applications such as AnyDesk, WebEx and TeamViewer to install, troubleshoot and configure applications anddigital signature certificates. - Providing timely database reports to competent authority for effective project monitoring\n"
      ],
      "metadata": {
        "id": "xdUfbV4QAL0P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " The officer was involved in - Usage of Digital Signature Certificates for user authentication and role based access of databases - Virtual Private Network to access IVFRT applications - Encrypted private data is safely and securely sent over the public network via crypto tokens - Use of remote desktop applications like AnyDesk, WebEx and TeamViewer to install, troubleshoot and configure applications and digital signature certificates. - Providing timely database reports to competent authority for effective project monitoring"
      ],
      "metadata": {
        "id": "WTc8ZMLCHYeK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " The officer was involved in - Usage of Digital Signature Certificates for user authentication and role based access of databases - Virtual Private Network to access IVFRT applications - Encrypted private data is safely and securely sent over the public network via crypto tokens - Use of remote desktop applications like AnyDesk, WebEx and TeamViewer to install, troubleshoot and configure applications and digital signature certificates. - Providing timely database reports to competent authority for effective project monitoring\n"
      ],
      "metadata": {
        "id": "9f4IZwvlGtHI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " The officer was involved in - Usage of Digital Signature Certificates for user authentication and role based access of databases - Virtual Private Network to access IVFRT applications - Encrypted private data is safely and securely sent over the public network via crypto tokens - Use of remote desktop applications like AnyDesk, WebEx and TeamViewer to install, troubleshoot and configure applications and digital signature certificates. - Providing timely database reports to competent authority for effective project monitoring\n"
      ],
      "metadata": {
        "id": "iZlCvHtGGqBH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " The officer was involved in - Implementation of e-Sign in various online personnel and administrative applications to facilitate workflow automation. - Various services and system had been merged into a single dashboard for Digital NIC portal.- KMS platform to share the knowledge and expertise of its employees among pan peers. - Centralised Sanction Management System has been developed and implemented for top management, it provides them the live snapshot of budget details i.e. allocation, expenditure and balance in various budget heads for all the DDO's of NIC.\n"
      ],
      "metadata": {
        "id": "3asWcXj8jXkL"
      }
    }
  ]
}